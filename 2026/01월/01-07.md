# 🤖 AI 뉴스 - 2026년 01월 07일

## 📑 목차

<!-- TOC_START -->
1. [[신년기획⑤] 탄소를 줄이는 길은 하나가 아니다](#신년기획⑤-탄소를-줄이는-길은-하나가-아니다)
2. ['클로드 코드' 제작자가 공개한 제품 사용법이 화제가 된 이유는](#클로드-코드-제작자가-공개한-제품-사용법이-화제가-된-이유는)
3. [AI가 생각하는 2026년 AI 주요 이슈는?](#ai가-생각하는-2026년-ai-주요-이슈는)
4. [SKT 정예팀, 'A.X K1' 기술 보고서 공개...수학·코딩 벤치마크에서 딥시크-V3.1 대비 성능 각각...](#skt-정예팀-ax-k1-기술-보고서-공개수학코딩-벤치마크에서-딥시크-v31-대비-성능-각각-102-110로-앞서)
5. [NXP, SDV 위한 신규 S32N7 프로세서 시리즈 출시...시스템 복잡성 줄이고, AI 기반 혁신](#nxp-sdv-위한-신규-s32n7-프로세서-시리즈-출시시스템-복잡성-줄이고-ai-기반-혁신)
6. ['스노우플레이크 코텍스 AI'에서 '제미나이 3' 모델 지원...데이터 이동 없이 개발·배포·확장 가속화](#스노우플레이크-코텍스-ai에서-제미나이-3-모델-지원데이터-이동-없이-개발배포확장-가속화)
7. [젠슨 황 CEO, 기술 분야 최고 권위의 '2026년 IEEE 최고 명예 메달' 수상자로 선정](#젠슨-황-ceo-기술-분야-최고-권위의-2026년-ieee-최고-명예-메달-수상자로-선정)
8. [삼성전자, CES 2026서 '삼성 기술 포럼' 열고 '인간 중심 디자인' 강조](#삼성전자-ces-2026서-삼성-기술-포럼-열고-인간-중심-디자인-강조)
9. [레드햇, 엔비디아와 가속화된 '엔터프라이즈 AI' 위한 개방형 혁신](#레드햇-엔비디아와-가속화된-엔터프라이즈-ai-위한-개방형-혁신)
<!-- TOC_END -->

---

### [신년기획⑤] 탄소를 줄이는 길은 하나가 아니다

> 📅 **2026-01-07** | **📌 일반** | 기타 | AI타임스
> 🏷️ 기타

**💡 요약**
[신년기획⑤] 탄소를 줄이는 길은 하나가 아니다

<details>
<summary><b>📄 원문 보기</b></summary>

요즘 뉴스에서 이런 말을 자주 듣는다. "탄소중립이 필요하다", "탄소를 줄이지 않으면 안 된다", 그러다 보면 이런 걱정도 생긴다. "그럼 공장을 없애야 하는 건가?" "일자리는 어떻게 되는 거지?" 하지만 탄소를 줄이는 방법은 하나가 아니다.

여수산단 모습

먼저 '탄소'가 뭔지부터 다시 보자. 탄소는 공장에서만 나오는 게 아니다. 전기를 만들 때, 기름과 가스를 쓸 때, 철을 만들 때, 에너지를 쓰면 어느 정도는 이산화탄소(CO₂)가 나온다.

동부권 산업은 나라를 먹여 살린 대신, 탄소도 많이 배출해 왔다. 그런데 이제 세상은 말한다. "탄소를 줄이지 않으면 물건을 사지 않겠다." 그래서 선택이 필요해졌다.

첫 번째 방법은 일하는 방식을 바꾸는 것이다. 기름·가스는 전기로, 오래된 설비는 새 설비로, 이렇게 하면 탄소가 줄어든다. 하지만 문제도 있다. 전기를 더 써야 한다.

설비를 바꾸는 데 돈이 많이 든다. 그래서 이 방법은 전기가 충분하지 않으면 공정 전환도 어렵다.

두 번째 방법은, 탄소를 아예 공중으로 보내지 않는 것이다. 이걸 CCUS라고 부른다. 공장에서 나오는 CO₂를 잡아서 액체로 만들거나, 다른 곳에 쓰거나 저장하는 방법이다.

이 방법의 장점은 이렇다. 공장을 바로 없애지 않아도 된다. 기존 산업을 살리면서 탄소를 줄일 수 있다. 그래서 여수산단 같은 곳에서는 이미 이 방법을 쓰기 시작했다.

그런데 CCUS도 만능은 아니다. CCUS는 좋은 방법이지만 혼자서는 어렵다. 왜냐하면, 설비가 크고, 비용이 많이 들고, 혼자 하기엔 부담이 크다.

그래서 중요한 질문이 나온다. "이걸 기업 하나가 할 건가, 아니면 산업단지 전체가 같이 할 건가?". 전문가들은 "동부권에서는 같이 쓰는 방식이 더 현실적이다"고 조언한다,

세 번째 방법은 탄소가 거의 없는 연료로 바꾸는 것이다. 대표적인 게 수소와 암모니아다. 이 연료를 쓰면 탄소가 거의 나오지 않는다. 그래서 "미래 연료"라고 불린다.

하지만 여기에도 조건이 있다. 안전하게 다룰 수 있는가, 저장할 곳이 있는가, 가격이 감당 가능한가, 이 모든 걸 항만·산업단지·안전 기준과 함께 준비해야 한다.

광양제철소 전경 (AI타임스DB)

그래서 중요한 건 '하나만 고르지 않는 것'이다. 여기서 가장 중요한 메시지인 탄소를 줄이는 길은 하나만 고르는 문제가 아니다.

동부권 산업에 맞는 방식은 당장은 CCUS로 버티고, 중간에는 공정을 전기로 바꾸고, 장기적으로 수소·새 연료로 간다. 이걸 단계적 전환이라고 한다.

서부권처럼 새로 만드는 산업도 중요하지만, 동부권은 이미 있는 산업을 어떻게 바꿔 살릴지가 더 중요하다.

탄소 전환은 비용, 안전, 일자리 모두와 연결된다. 그래서 필요한 것은 지역 전체의 약속과 계획이다. "이 지역은 이런 순서로 탄소를 줄이겠다." 이게 바로 동부권 발전전략의 한 축이다.

탄소를 줄인다는 건, 산업을 없앤다는 뜻이 아니다. 공장을 없애겠다는 말이 아니다. 산업을 살리는 방법을 바꾸겠다는 뜻이다.

동부권은 이미 산업이 있다. 이...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205346)

---

### '클로드 코드' 제작자가 공개한 제품 사용법이 화제가 된 이유는

> 📅 **2026-01-07** | **📌 일반** | Anthropic | AI타임스
> 🏷️ LLM, 추론 AI, 에이전트

**💡 요약**
[1월6일] '클로드 코드' 제작자가 공개한 제품 사용법이 화제가 된 이유는

<details>
<summary><b>📄 원문 보기</b></summary>

'클로드 코드'의 제작자가 공개한 코딩 에이전트 활용법이 개발자 사이에서 큰 화제입니다.

보리스 체르니 앤트로픽 책임자는 지난 3일(현지시간) X(트위터)를 통해 "많은 사람들이 내가 클로드 코드를 어떻게 사용하는지 궁금해해서 작업 환경을 조금 보여드리려고 한다"라는 글을 올렸습니다.

그가 밝힌 내용은 대략 다섯가지로 구분할 수 있습니다.

가장 먼저 꼽은 것은 '병렬 실행'입니다. 5개의 클로드 프로그램을 터미널에서 동시에 실행하고, 웹에서도 추가 에이전트를 사용하는 것입니다. 이때 iTerm2 시스템 알림을 활용해 각 에이전트에 입력이 필요할 때를 효율적으로 파악하고 관리합니다.

각 에이전트는 독립적인 임무를 수행합니다. 예를 들어, 에이전트 1은 테스트 스위트를 실행하고, 에이전트 2는 기존 모듈 리팩토링을 담당하며, 에이전트 3는 문서를 작성하고, 에이전트 4와 5는 기타 개발 작업을 맡는 식입니다.

이런 병렬 에이전트 실행으로 개발자 한명이 소규모의 엔지니어링 팀을 지휘하는 것과 같은 생산성을 발휘할 수 있다는 것을 보여줍니다. 이전처럼 개발자 한명이 하나의 임무만 처리하는 것이 아니라, 적은 인력으로 더 많은 것을 처리할 수 있다는 내용입니다.

'가장 느리지만, 가장 똑똑한 모델을 사용한다'라는 두번째 전략도 흥미롭습니다.

그는 "모든 것에 능통한 클로드 오퍼스 4.5를 사용한다"라며 "내가 사용해 본 코딩 모델 중 최고이며, 소네트보다 크고 느리긴 하지만, 직접 조작할 필요가 적고 도구 활용 능력이 뛰어나기 때문에 결과적으로는 더 작은 모델을 사용하는 것보다 거의 항상 더 빠르다"라며 밝혔습니다.

일반적으로 업계와 개발자들은 모델의 지연시간(Latency)에 민감합니다. 즉, 더 빠른 모델을 선호합니다.

그러나 체르니 책임자는 느리지만 사고 기능과 도구 활용 능력이 뛰어나, 결과적으로 인간의 수정 비용을 줄여주는 모델을 선호한다는 것입니다. 이는 AI의 병목 현상이 토큰 생성 속도가 아닌, AI의 오류를 수정하는 데 드는 인간의 시간이라는 점을 강조하는 것입니다. 더 똑똑한 모델을 통해 사전 계산 비용을 지불함으로써 궁극적으로는 더 빠르게 결과를 얻는다는 내용입니다.

최근 부쩍 강조되는 모델의 맥락 유지나 지속 학습에 대한 노하우도 공개했습니다. 체르니 책임자의 팀은 코드 저장소에 'CLAUDE.md'라는 파일을 유지합니다.

이는 클로드 코드가 실수를 할 때마다 이를 교훈으로 삼아 CLAUDE.md 파일에 규칙을 추가하는 것입니다. 결국 에이전트는 팀과의 작업이 늘어날수록, 코딩 스타일과 아키텍처 규칙을 자체적으로 학습하고 개선해 스스로 오류를 수정하는 유기체가 될 수 있습니다.

반복적인 작업 흐름을 자동화, 개발의 지루한 부분을 제거하는 방법도 소개했습니다. 이를 위해 그는 '/commit-push-pr'과 같은 슬래시 명령어를 즐겨 사용한다고 밝혔습니다. 이를 통해 Git 버전 관리 프로세스 전체를 에이전트가 자율적으로 처리하도록 하는 것입니다.

또 특정 개발 수명 주기 단계를 위해 코드 간소화 에이...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205321)

---

### AI가 생각하는 2026년 AI 주요 이슈는?

> 📅 **2026-01-07** | **📌 일반** | 기타 | AI타임스
> 🏷️ 기타

**💡 요약**
AI가 생각하는 2026년 AI 주요 이슈는?

<details>
<summary><b>📄 원문 보기</b></summary>

www.aitimes.com

발행일: 2026-01-07 08:03 (수)

로그인

한국어

일본어

중국어

뉴스레터 신청

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205350)

---

### SKT 정예팀, 'A.X K1' 기술 보고서 공개...수학·코딩 벤치마크에서 딥시크-V3.1 대비 성능 각각 102%, 110%로 앞서

> 📅 **2026-01-07** | **📌 일반** | NVIDIA | 인공지능신문
> 🏷️ 추론 AI, 멀티모달, 오픈소스

**💡 요약**
SKT 정예팀, 'A.X K1' 기술 보고서 공개...수학·코딩 벤치마크에서 딥시크-V3.1 대비 성능 각각 102%, 110%로 앞서

<details>
<summary><b>📄 원문 보기</b></summary>

로고 이미지

SK텔레콤 정예팀은 매개변수 519B(5,190억 개) 규모의 초거대 AI 모델 ‘A.X K1(에이닷엑스 케이원)’의 기술 보고서(아래 첨부)를 오픈소스 플랫폼 허깅페이스에 7일 공개했다. SK텔레콤 정예팀은 4개월여의 짧은 개발기간과 제한된 GPU 자원에도 불구하고 다양한 기술과 효율성을 극대화한 설계로 국내 첫 500B 이상 초거대 모델 A.X K1을 완성했다.

한정된 시간 안에 519B 규모를 갖췄음에도 주요 벤치마크에서 딥시크-V3.1 등 세계적으로 많이 활용되는 초거대 모델과 유사하거나 더 높은 성능을 달성한 점은 고무적이다. 통상 매개변수가 많아질수록 최적화 시간과 GPU 자원 투입이 늘어날 수밖에 없는데, 타 정예팀 대비 최소 2배 이상의 모델 규모임에도 높은 성능까지 확보해 주목할만하다.

A.X K1은 향후 추가 연구 기간에 따라 더 많은 컴퓨팅 자원과 데이터를 투입해 성능을 더욱 높일 수 있는 모델이다. SKT는 연내 멀티모달 기능을 추가하고 조 단위 파라미터로 확대할 계획이다.

SKT 정예팀은 1,000개의 GPU 자원을 활용해 A.X K1 학습을 진행했다. 학습 기간과 GPU 규모를 바탕으로 가능한 총 학습량을 추산하고, 이를 바탕으로 최대 모델 크기를 스케일링 이론(모델 성능은 투입 자원에 비례한다는 이론)에 근거해 설계했다.

그 결과 세계적으로도 독창적인 매개변수 구조인 519B 규모의 모델을 목표로 정하고 약 10조(10T) 개의 데이터를 투입해 학습했다. 정예팀은 개발기간 동안 상시 1,000개 이상의 GPU를 인공지능 훈련에 활용했다. 투여된 GPU 자원 대비 효과를 극대화하기 위해 최적의 학습 연산량을 수학적으로 설계하고 관리했다. 특히 A.X K1은 이번 개발기간 동안 정부 지원을 받지 않고 자체 GPU 조달만으로 목표를 달성했다는 점에서 더욱 의미가 깊다.

모델 학습에는 웹 데이터, 코드, 이공계 데이터 (STEM, Science, Technology, Engineering, Mathematics), 추론 데이터 등 다양한 고품질 데이터를 활용했다. 한국어 특화 PDF 문서를 파싱(Parsing) 및 합성 데이터를 생성했고, 난이도별 커리큘럼 학습 방식도 적용했다.

A.X K1은 수학과 코딩 등 초거대 인공지능 모델의 능력을 필요로 하는 분야에서 우수한 성능을 구현했다. 이번 보고서에 기술된 벤치마크 지표는 매개변수 6,850억 개(685B)의 ‘딥시크-V3.1’, 매개변수 3,570개(357B)의 ‘GLM-4.6’ 오픈소스 모델과 비교해 규모 대비 성능을 비교할 수 있도록 했다.

수학은 AIME25 벤치마크에서 89.8점을 받아 딥시크-V3.1 모델(88.4점) 대비 102% 수준으로 앞선 성능을 확인했다. AIME25는 미국 고등학생 수학 올림피아드 문제로 AI의 수학 실력을 측정하며, 창의적이고 복잡한 난이도의 문제가 출제된다.

코딩 활용도 측면에서 측정한 LiveCodeBench는 영어 기반 75.8점, 한국어 기반 73.1점을 기록하며 실시간 코딩 문제 해결 능력을...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38037)

---

### NXP, SDV 위한 신규 S32N7 프로세서 시리즈 출시...시스템 복잡성 줄이고, AI 기반 혁신

> 📅 **2026-01-07** | **📌 일반** | 기타 | 인공지능신문
> 🏷️ 기타

**💡 요약**
NXP, SDV 위한 신규 S32N7 프로세서 시리즈 출시...시스템 복잡성 줄이고, AI 기반 혁신

<details>
<summary><b>📄 원문 보기</b></summary>

이미지:NXP

NXP 반도체가 미국 라스베이거스에서 열린 세계 최대 IT·가전 전시회 CES 2026에서 S32N7 초통합(super-integration) 프로세서 시리즈를 공개했다. 이 시리즈는 S32N55와 동일한 5nm 공정을 기반으로 하며, 자동차 제조사가 구동계, 주행 제어, 차체, 게이트웨이, 안전 영역 등 모든 차량의 핵심 기능을 디지털화할 수 있도록 지원한다. 이를 통해 시스템 복잡성을 줄이고, 인공지능(AI) 기반 혁신을 대규모로 구현할 수 있다.

S32N7 시리즈는 차량 핵심부에 소프트웨어와 데이터를 단일 중앙 집중형 허브로 통합하도록 설계됐으며, 확고한 안전성과 보안성을 제공한다. 이 새로운 프로세서 시리즈는 자동차 제조사가 차량 아키텍처를 크게 단순화할 수 있도록 지원한다. 수십 개의 하드웨어 모듈을 제거하고 배선, 전자 장치, 소프트웨어 효율성을 향상시켜 총소유비용(total cost of ownership, TCO)을 최대 20%까지 절감할 수 있다.

또한, S32N7 시리즈는 지능을 중앙 집중화해 자동차 제조사가 차량 전체에 걸쳐 AI 혁신을 확장할 수 있는 기반을 확보할 수 있다. 이는 소프트웨어 비즈니스 모델을 가속화하고 맞춤형 주행, 예지보전, 가상 센서와 같은 지능형 기능을 구현한다. S32N7 시리즈의 고성능 데이터 백본(backbone)은 차량을 재설계하지 않고도 최신 AI 실리콘으로 업그레이드할 수 있는 미래 지향적인 경로를 제공한다. 이로써 자동차 제조사가 지속적으로 차별화할 수 있도록 보장한다.

S32N7 이미지

S32N7은 소프트웨어 정의 미래를 위해 설계됐으며, 차량의 핵심 기능을 디지털화해 차량 아키텍처를 재정의한다. 이로써 모델과 브랜드를 아우르는 확장 가능한 하드웨어와 소프트웨어를 구현한다. 소프트웨어의 중앙 집중화는 개발을 가속화하고 TCO를 절감한다. 핵심 차량 데이터 접근성과 높은 컴퓨팅 성능을 바탕으로, S32N7 시리즈는 차세대 모빌리티를 위한 중앙 AI 제어 포인트로 기능한다.

보쉬와 함께 소프트웨어 정의 모빌리티 가속

보쉬(Bosch)는 자사 차량 통합 플랫폼에 S32N7을 최초로 적용했다. NXP와 보쉬는 공동으로 레퍼런스 설계, 안전 프레임워크, 하드웨어 통합, 전문가 지원 프로그램을 개발해 시스템 배포를 가속화하고 초기 도입 업체의 통합 부담을 줄였다.

보쉬 모빌리티(Bosch Mobility)의 컴퓨팅 강화 부문 수석 부사장 마티아스 브로이니히(Matthias Breunig)는 “보쉬의 차량 통합 플랫폼은 진정한 소프트웨어 정의 차량(software-defined vehicle, SDV)을 구현하는 새로운 E/E 아키텍처의 핵심이다. NXP의 S32N7 프로세서 시리즈에 대한 양사의 긴밀한 협력은 NXP의 선도적인 반도체 기술과 우리의 심층적인 시스템 전문성, 최고 수준의 안전과 보안 기준을 어떻게 결합했는지 보여준다.

최초의 NXP S32N7 실리콘으로 보쉬 ECU 샘플을 준비함으로써, 우리는 고객에게 개발을 위한 상당한 선행 이점을 제공해 차세대...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38035)

---

### '스노우플레이크 코텍스 AI'에서 '제미나이 3' 모델 지원...데이터 이동 없이 개발·배포·확장 가속화

> 📅 **2026-01-07** | **📌 일반** | Google | 인공지능신문
> 🏷️ LLM, 추론 AI, 에이전트

**💡 요약**
'스노우플레이크 코텍스 AI'에서 '제미나이 3' 모델 지원...데이터 이동 없이 개발·배포·확장 가속화

<details>
<summary><b>📄 원문 보기</b></summary>

이미지:본지DB

인공지능 데이터 클라우드 기업 스노우플레이크(Snowflake)가 구글 클라우드(Google Cloud)와 공동 시장 진출(Go-To-Market, GTM) 전략을 본격화하고 양사 엔터프라이즈 고객의 AI 혁신을 지원한다고 7일 밝혔다.

이를 통해 ‘스노우플레이크 코텍스 AI(Snowflake Cortex AI)’에서 구글 클라우드 자체 대규모언어모델(LLM)인 ‘제미나이 3’를 기본으로 사용할 수 있게 된다. 고객들은 플랫폼 간 데이터 이동이나 복제 없이 스노우플레이크의 안전한 거버넌스 기반 데이터 환경에서 제미나이의 지능형 데이터 에이전트를 포함한 생성형 AI 애플리케이션을 개발, 배포, 확장할 수 있다.

이번 협력 확대로 양사는 GTM 전략을 강화해 공동 고객 참여, 공동판매(co-sell), 구글 클라우드 마켓플레이스(Google Cloud Marketplace) 거래 등을 지원한다. 글로벌 시장 확장에도 속도를 낸다. 양사는 최근 사우디아라비아에서 구글 클라우드 기반 스노우플레이크를 출시한 데에 이어, 2026년 호주 멜버른에서도 출시하며 협력할 예정이다.

이와 함께 구글 클라우드 액시온(Google Cloud Axion) 기반 C4A 가상머신(VM)에서 스노우플레이크 2세대 표준 웨어하우스(Snowflake Gen2 Warehouses)를 프로덕션 환경에서 제공하는 주요 인프라 업그레이드를 통해 가격 대비 성능 이점을 한층 강화했다.

한편 금융 서비스, 헬스케어, 제조, 리테일 및 공급망, 기술, 데이터 분석 등 다양한 산업의 기업들이 이미 스노우플레이크와 구글 클라우드의 통합 솔루션을 도입해 데이터 기반을 현대화하고 AI 혁신을 가속화하고 있다.

대표적으로 데이터 관리 플랫폼 기업 파이브트랜(Fivetran)과 재무 전문 소프트웨어 기업 블랙라인(BlackLine)은 구글 클라우드 기반 스노우플레이크 AI 데이터 클라우드를 활용해 실시간 분석, AI 모델 배포, 생태계 전반에 걸친 고도화된 데이터 거버넌스를 구현하고 있다.

조지 프레이저(George Fraser) 파이브트랜 CEO는 “스노우플레이크와 구글 클라우드 통합 솔루션을 통해 기업들은 데이터를 단순 저장하고 기본 쿼리를 실행하는 수준을 넘어 실제 비즈니스 운영 데이터를 기반으로 직접 질문하고 즉각적인 인사이트를 얻을 수 있게 됐다”며 “파이브트랜은 연결성 및 거버넌스를 갖춘 데이터 파운데이션을 제공해 스노우플레이크 코텍스 AI 내 제미나이가 고객 데이터를 기반으로 실제 사고, 추론할 수 있는 환경을 구현했다. 여러 주에 걸쳐 진행되던 개발 작업이 이제는 수일 내로 줄어들었다”고 말했다.

마이클 거스텐하버(Michael Gerstenhaber) 구글 클라우드 버텍스 AI 및 AI 에이전트 제품 관리 부사장은 “이번 스노우플레이크와의 협력 확대는 기업이 더 빠르게 엔터프라이즈 AI 혁신을 실현할 수 있도록 지원하는 데 중점을 뒀다”며 “무엇보다 제미나이 모델을 스노우플레이크 내에서 직접 활용할 수 있게 됨으로써 양사 고객들이 거버넌스가 적용...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38034)

---

### 젠슨 황 CEO, 기술 분야 최고 권위의 '2026년 IEEE 최고 명예 메달' 수상자로 선정

> 📅 **2026-01-07** | **📌 일반** | OpenAI | 인공지능신문
> 🏷️ LLM, 로보틱스

**💡 요약**
젠슨 황 CEO, 기술 분야 최고 권위의 '2026년 IEEE 최고 명예 메달' 수상자로 선정

<details>
<summary><b>📄 원문 보기</b></summary>

젠슨 황 CEO 캐릭터 이미지:본지DB

전 세계 50만 명 이상의 회원을 보유한 세계 최대 기술 전문 조직이자 '인류를 위한 기술 발전'을 사명으로 하는 IEEE(Institute of Electrical and Electronics Engineers)가 엔비디아(NVIDIA) 창립자 겸 최고경영자(CEO)인 젠슨 황(Jensen Huang)을 최고 영예인 '2026 IEEE 최고 명예 메달(IEEE Medal of Honor)' 수상자로 선정했다고 7일 발표했다. 이번 수상에는 200만 달러의 상금이 함께 수여된다.

젠슨 황은 가속 컴퓨팅 분야에서의 선구적인 리더십과 혁신적인 업적을 통해 엔비디아를 기술 혁신의 최전선으로 이끈 공로를 높이 평가받았다. 그는 최근 엘리자베스 여왕 공학상(Queen Elizabeth Prize for Engineering), 파이낸셜타임스(Financial Times) 및 타임(TIME) 매거진의 '올해의 인물', 스티븐 호킹 교수 펠로십(Professor Stephen Hawking Fellowship) 수상에 이어 또 하나의 역사적인 이정표를 세웠다.

그의 리더십 아래 엔비디아는 2025년 10월 시가총액 5조 달러를 돌파한 최초의 기업이 됐다. 엔비디아는 1999년 세계 최초로 그래픽처리장치(GPU)를 개발해 컴퓨팅 산업에 혁명을 일으켰다. 이러한 기술적 돌파구는 의료, 공학, 로보틱스, 자율주행차, 제조 등 다양한 분야의 혁신을 가능하게 했으며, 가속 컴퓨팅에 대한 그의 통찰은 오늘날 인공지능(AI) 기술과 산업 혁명의 토대를 마련했다.

메리 엘런 랜들(Mary Ellen Randall) IEEE 회장은 "IEEE 최고 명예 메달은 커리어에서 이룰 수 있는 최고의 성취를 상징한다"며 "젠슨 황의 공헌은 기술의 한계를 넓혔고, 아직 상상조차 할 수 없는 미래 혁신을 가능하게 했다. IEEE는 우리 분야의 탁월함을 정의할 뿐 아니라 차세대 엔지니어와 기술자들에게 영감을 주는 업적을 기리게 돼 자랑스럽다"라고 밝혔다.

1917년에 제정된 IEEE 최고 명예 메달은 기술과 공학의 발전에 지대한 영향을 미친 개인에게 수여된다. 수상자들은 새로운 혁신을 과감히 구상하고 가능성의 한계를 확장해 왔으며, 이들의 성과는 오늘날 기술자들이 세상을 더 혁신적이고 나은 곳으로 만들도록 영감을 준다.

이러한 선구자들은 파격적인 아이디어를 세상을 바꾸는 현실로 전환하여 우리의 삶과 일, 연결 방식을 재편해 왔다. 젠슨 황은 인터넷 아키텍처의 빈트 서프(Vinton G. Cerf)와 로버트 칸(Robert Kahn), GPS의 브래드퍼드 W. 파킨슨(Bradford W. Parkinson), 반도체의 모리스 창(Morris Chang) 등 현대인의 삶을 변화시킨 역대 수상자들의 명맥을 잇게 됐다.

엔비디아의 가속 컴퓨팅 플랫폼은 챗GPT(ChatGPT)와 같은 생성형 AI 모델의 구현부터 세계 최고 수준의 AI 팩토리와 데이터센터 구축에 이르기까지 모든 산업의 동력이 되고 있다. 혁신에 대한 젠슨 황의 확고한 의...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38033)

---

### 삼성전자, CES 2026서 '삼성 기술 포럼' 열고 '인간 중심 디자인' 강조

> 📅 **2026-01-07** | **📌 일반** | 기타 | 인공지능신문
> 🏷️ LLM, 멀티모달, 음성/오디오

**💡 요약**
삼성전자, CES 2026서 '삼성 기술 포럼' 열고 '인간 중심 디자인' 강조

<details>
<summary><b>📄 원문 보기</b></summary>

삼성전자가 세계 최대 전자 전시회 CES 2026에서 '삼성 기술 포럼(Samsung Tech Forum)'을 갖고 AI 시대에 발맞춘 기술 디자인의 새로운 방향성으로 '인간 중심 디자인(Human Centered Design)' 비전을 제시했다. (왼쪽부터)파비오 노벰브레(Fabio Novembre), 카림 라시드(Karim Rashid), 마우로 포르치니(Mauro Porcini), 데비 밀먼(Debbie Millman)

삼성전자가 세계 최대 전자 전시회 CES 2026에서 '삼성 기술 포럼(Samsung Tech Forum)'을 열고 AI 시대의 '기술의 인간적인 면모(The Human Side of Tech: Designing a Future Worth Loving)'를 주제로 패널 토론을 진행했다.

삼성전자는 5일부터 6일(현지시간) 양일간 미국 라스베이거스 윈 호텔(Wynn and Encore Las Vegas)에 마련된 삼성전자 단독 전시관에서 가전 연결 경험, TV 서비스,보안, 디자인 등을 주제로 총 4개 세션의 '삼성 기술 포럼'을 진행했다.

6일 '삼성 기술 포럼'의 마지막 패널 토론에는 삼성전자 최고디자인책임자(CDO) 마우로 포르치니(Mauro Porcini) 사장과 카림 라시드(Karim Rashid), 파비오 노벰브레(Fabio Novembre) 등 세계적인 디자이너들이 참여했다.

토론의 사회는 디자인 전문 팟캐스트 '디자인 매터스(Design Matters)'의 진행자인 데비 밀먼(Debbie Millman)이 맡았다. 이번 토론에서는 인공지능 시대에 디자인을 통해 기술이 표현력 있고 따뜻하며 감성적으로 공감 가능한 존재로 진화할 수 있는 방안에 대해 깊이 있는 논의가 진행됐다.

기술 차별화의 핵심은 '사람 중심의 관점에서 출발한 디자인'

사회를 맡은 데비 밀먼은 "지난 20년 간 기술의 디자인은 미니멀리즘이 지배적이었다"며 "기술이 사용성을 넘어 개성과 정체성을 반영하는 역할을 하기 위한 새로운 디자인 방향을 논의할 시점"이라고 화두를 던졌다.

패널들은 모든 의미있는 혁신 뒤에 사람 중심의 디자인이 있다는 것에 공감하며, 단순한 제품을 넘어 사람들의 삶과 경험·가치에 부합하는 의미를 창출하는 것이 중요하다고 강조했다. 파비오 노벰브레는 "우리는 디자인을 통해 행복을 추구하며, 불가능을 가능으로 만든다"라고 말했다. 또 기술 환경이 빠르게 변화하고 접근성과 기술 격차가 줄어드는 가운데, 기술 차별화의 핵심은 사람 중심의 관점에서 출발한 디자인이라는 데 의견을 모았다.

삼성전자 최고디자인책임자(CDO) 마우로 포르치니(Mauro Porcini) 사장

마우로 포르치니 사장은 "사람 중심의 접근은 미래를 위한 당연한 책임"이라고 말하며 "당위성을 넘어 전략적으로나 경제적 측면에도 필수적인 요소라고 생각한다"라고 말했다. 이어 "삼성전자 디자인의 목표는 기술을 통해 사람들의 삶의 질을 풍요롭게 하는 것"이라며 "삼성전자가 디자인과 기술을 통해 더 오래 건강하게 살고 더 나은 삶을 누리며 자유롭게 자신...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38032)

---

### 레드햇, 엔비디아와 가속화된 '엔터프라이즈 AI' 위한 개방형 혁신

> 📅 **2026-01-07** | **📌 일반** | NVIDIA | 인공지능신문
> 🏷️ 추론 AI, 에이전트, 멀티모달

**💡 요약**
레드햇, 엔비디아와 가속화된 '엔터프라이즈 AI' 위한 개방형 혁신

<details>
<summary><b>📄 원문 보기</b></summary>

각 사 로고 이미지

글로벌 오픈소스 솔루션 선도기업 레드햇(Red Hat)은 엔비디아와의 협업을 확장한다고 6일(현지시간) 발표했다. 이번 협업은 엔터프라이즈 오픈소스 기술을 급변하는 엔터프라이즈 인공지능(AI) 발전과 랙 스케일(rack-scale) AI 혁신에 맞춰 조율하는 것을 목표로 한다.

산업 전반에서 개별 서버를 넘어 통합된 고밀도 시스템으로 나아가는 가운데, 레드햇은 ‘엔비디아용 레드햇 엔터프라이즈 리눅스(Red Hat Enterprise Linux for NVIDIA)’를 통해 이러한 전환의 출발점을 제공하고자 한다. ‘엔비디아용 레드햇 엔터프라이즈 리눅스’는 엔비디아 루빈(NVIDIA Rubin) 플랫폼에 최적화되고 레드햇 오픈시프트(Red Hat OpenShift)와 레드햇 AI(Red Hat AI)에서의 향후 생산성 향상을 위해 튜닝된 세계 최고의 엔터프라이즈 리눅스 플랫폼의 특별 에디션이다.

맷 힉스(Matt Hicks) 레드햇 사장 겸 CEO는 "엔비디아의 아키텍처 혁신은 AI를 필수 기술로 만들었으며, 컴퓨팅 스택이 산업의 미래를 정의할 것임을 증명했다"며 "이러한 변화를 출시 시점에 맞춰 대응하기 위해 레드햇과 엔비디아는 레드햇의 하이브리드 클라우드 및 AI 포트폴리오 전반에서 최신 엔비디아 아키텍처에 대한 0일 차(Day 0) 지원을 제공할 계획이다. 양사는 오픈소스의 역량을 통해 차세대 엔터프라이즈 AI를 가속화하고 있다"라고 말했다.

젠슨 황(Jensen Huang) 엔비디아 창립자 겸 CEO는 "레드햇은 오픈소스 소프트웨어로 엔터프라이즈 컴퓨팅을 혁신했다"며 "AI 시대에는 칩과 시스템부터 미들웨어, 모델, 그리고 AI 라이프사이클에 이르기까지 컴퓨팅 스택 전체가 근본적으로 재창조되고 있다. 양사는 베라 루빈 플랫폼을 시작으로 기업에 AI를 제공하기 위해 오픈소스를 산업화하고 있다"라고 말했다.

2026년을 맞아 많은 기업이 하향식(top-down) 전략과 AI 에이전트 및 최신 기술이 통합된 중앙 집중식 AI 툴박스를 활용해 AI를 실험 단계에서 생산 단계로 전환할 준비를 하고 있다. 그러나 이러한 전환을 위해서는 기반 아키텍처부터 그 위에서 구동되는 소프트웨어에 이르기까지 안정적이고 고성능이며 보다 보안이 강화된 인프라 스택이 필수적이다.

새로운 엔비디아 베라(NVIDIA Vera) CPU와 최첨단 엔비디아 루빈(NVIDIA Rubin) GPU를 탑재한 엔비디아 루빈 플랫폼은 에이전틱 AI와 고급 추론 분야에서 비약적인 도약을 실현하도록 설계됐다. 이 새로운 플랫폼에 대한 0일 차 지원을 시작으로 레드햇은 자사의 하이브리드 클라우드 포트폴리오를 엔비디아의 혁신 기술에 최적화함으로써 기업들이 하이브리드 클라우드 전반에서 엔터프라이즈급 신뢰성과 일관된 운영 모델을 바탕으로 AI 이니셔티브를 보다 원활하게 확장할 수 있도록 지원할 계획이다.

기가스케일 AI 팩토리의 근본적인 혁신

엔비디아 베라 루빈 플랫폼은 기가스케일(gigascale) AI 팩토리(AI Factory)를 위한 가장 전력 효...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38031)

---
