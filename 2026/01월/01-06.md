# 🤖 AI 뉴스 - 2026년 01월 06일

## 📑 목차

<!-- TOC_START -->
1. [업스테이지, '솔라 오픈' 오픈 소스 공개..."딥시크-R1 넘은 프롬 스크래치 모델"](#업스테이지-솔라-오픈-오픈-소스-공개딥시크-r1-넘은-프롬-스크래치-모델)
2. [[신년기획④] 발전소는 서부에, 일자리는 동부에](#신년기획④-발전소는-서부에-일자리는-동부에)
3. [기업 AI 도입의 핵심으로 떠오른 '통합 온톨로지'란](#기업-ai-도입의-핵심으로-떠오른-통합-온톨로지란)
4. [﻿"모바일·TV·가전에 AI 통합"... 삼성전자, CES서 'AI 대중화' 비전 공개](#모바일tv가전에-ai-통합-삼성전자-ces서-ai-대중화-비전-공개)
5. [차세대 AI PC를 위한 프로세서 '인텔 코어 Ultra 시리즈 3' 출시](#차세대-ai-pc를-위한-프로세서-인텔-코어-ultra-시리즈-3-출시)
6. [엔비디아 젠슨 황, “로보틱스 분야에도 ‘챗GPT 시대’가 도래했다](#엔비디아-젠슨-황-로보틱스-분야에도-챗gpt-시대가-도래했다)
7. [SK AX ‘생성형AI 활용 자격증’ 국내 첫 정부공인…산업 AI전환 가속 돕는다](#sk-ax-생성형ai-활용-자격증-국내-첫-정부공인산업-ai전환-가속-돕는다)
8. [퀄컴, ‘피지컬 AI’ 전면전 선언…가정용 로봇부터 휴머노이드까지 아우르는 로보틱스 풀스택 공개](#퀄컴-피지컬-ai-전면전-선언가정용-로봇부터-휴머노이드까지-아우르는-로보틱스-풀스택-공개)
9. ["딥시크의 mHC, LLM 학습 통념 깼지만 실제 구현은 난제"](#딥시크의-mhc-llm-학습-통념-깼지만-실제-구현은-난제)
10. [오픈AI 추론 모델 이끈 연구 책임자 퇴사...'IMO 금메달 모델' 개발 끝났나](#오픈ai-추론-모델-이끈-연구-책임자-퇴사imo-금메달-모델-개발-끝났나)
11. [엔비디아, 자율주행·로봇용 오픈 소스 제품군 '알파마요' 출시](#엔비디아-자율주행로봇용-오픈-소스-제품군-알파마요-출시)
12. [애플 출신 로봇 스타트업이 5년 만에 스텔스를 벗어난 이유는](#애플-출신-로봇-스타트업이-5년-만에-스텔스를-벗어난-이유는)
13. [텐센트, 사용자에게 욕설한 AI 챗봇 문제로 사과...중국 첫 사례로 주목](#텐센트-사용자에게-욕설한-ai-챗봇-문제로-사과중국-첫-사례로-주목)
14. ["AI가 설계한 분자 센서, 조기 암 진단의 새 길 열다!"... MIT 연구진, 소변 한 방울로 30종 암...](#ai가-설계한-분자-센서-조기-암-진단의-새-길-열다-mit-연구진-소변-한-방울로-30종-암-동시-판별)
15. [마이크로소프트, ‘오스모스(Osmos)’ 인수... “AI 에이전트가 데이터 준비까지 맡는다”](#마이크로소프트-오스모스osmos-인수-ai-에이전트가-데이터-준비까지-맡는다)
16. [Why AI predictions are so hard](#why-ai-predictions-are-so-hard)
17. [Lenovo’s joining the bandwagon with concept AI glasses](#lenovos-joining-the-bandwagon-with-concept-ai-glasses)
18. [Jake Sullivan is furious that Trump destroyed his AI foreign...](#jake-sullivan-is-furious-that-trump-destroyed-his-ai-foreign-policy)
19. [Grok is undressing children — can the law stop it?](#grok-is-undressing-children-can-the-law-stop-it)
20. [Universal Music signs a new AI deal with Nvidia](#universal-music-signs-a-new-ai-deal-with-nvidia)
21. [AI moves into the real world as companion robots and pets](#ai-moves-into-the-real-world-as-companion-robots-and-pets)
22. [Vibe Bot is an AI agent that sits on your desk](#vibe-bot-is-an-ai-agent-that-sits-on-your-desk)
23. [Razer is making an AI anime waifu hologram for your desk](#razer-is-making-an-ai-anime-waifu-hologram-for-your-desk)
24. [Razer’s AI wearable is a headset with built-in cameras](#razers-ai-wearable-is-a-headset-with-built-in-cameras)
25. [Razer is making computers for AI developers now](#razer-is-making-computers-for-ai-developers-now)
26. [Reolink made a local AI hub for its security cameras](#reolink-made-a-local-ai-hub-for-its-security-cameras)
<!-- TOC_END -->

---

### 업스테이지, '솔라 오픈' 오픈 소스 공개..."딥시크-R1 넘은 프롬 스크래치 모델"

> 📅 **2026-01-06** | **📌 일반** | NVIDIA | AI타임스
> 🏷️ LLM, 에이전트, 오픈소스

**💡 요약**
업스테이지, '솔라 오픈' 오픈 소스 공개..."딥시크-R1 넘은 프롬 스크래치 모델"

<details>
<summary><b>📄 원문 보기</b></summary>

업스테이지(대표 김성훈)가 자체 개발한 거대언어모델(LLM) ‘솔라 오픈 100B’를 6일 오픈 소스로 전면 공개했다.

솔라 오픈은 업스테이지가 주관사로 참여 중인 과학기술정보통신부의 ‘독자 AI 파운데이션 모델 프로젝트’의 첫번째 결과물이다. 데이터 구축부터 학습에 이르는 과정 전반을 독자적으로 수행하는 ‘프롬 스크래치’ 방식으로 개발했다. 이를

허깅페이스에 공개

하는 동시에, 개발 과정과 기술적 세부 내용을 담은

테크 리포트도 발표

했다.

1020억 매개변수 모델인 솔라 오픈은 성능 면에서 글로벌 프런티어급 모델들과 어깨를 나란히 했다. ‘딥시크 R1’ 대비 사이즈는 15%에 불과하지만, 한국어(110%)와 영어(103%), 일본어(106%) 등 3개 국어 주요 벤치마크 평가에서 이를 상회하는 성과를 거뒀다.

한국어 능력은 압도적이다. 한국 문화 이해도(Hae-Rae v1.1), 한국어 지식(CLIcK) 등 주요 한국어 벤치마크에서는 딥시크-R1의 2배 이상 성능 격차를 보였으며, 오픈AI의 ‘gpt-oss-120B-미디엄’과 비교해도 100% 앞선 성능을 기록했다.

수학, 복합 지시 수행, 에이전트 등 고차원적 지식 영역에서도 딥시크-R1과 대등한 성능을 확보했다. 오픈AI gpt-oss-120B-미디엄과 비교해서도 종합 지식과 코드 작성 능력 등에서 대등한 경쟁력을 보였다.

고성능의 배경에는 약 20조 토큰 규모의 고품질 사전학습 데이터셋이 주효했다. 업스테이지는 대표적 ‘저자원 언어’인 한국어 데이터 부족을 극복하기 위해 다양한 합성 데이터와 금융·법률·의학 등 분야별 특화 데이터 등을 학습에 활용하고 다양한 데이터 학습 및 필터링 방법론을 고도화했다고 전했다.

업스테이지는 앞으로 데이터셋의 일부를 한국지능정보사회진흥원(NIA)의 ‘AI 허브’를 통해 개방해, 국내 AI 연구 생태계 활성화를 위한 공공재로 환원한다. 기업 경쟁력의 핵심 자산인 원천 데이터를 공개하는 것은 업계에서도 매우 이례적이며, 이는 생태계를 위한 결단이라고 강조했다.

솔라 오픈은 129개의 전문가 모델을 혼합한 MoE 구조를 통해 실제 연산에는 120억개 매개변수만 활성화하는 방식으로 효율을 극대화했다. 또, GPU 최적화를 통해 초당 토큰 처리량(TPS)을 약 80% 향상하고, 자체 강화 학습(RL) 프레임워크 ‘스냅PO(SnapPO)’를 개발해 학습 기간을 50% 단축했다. 이를 통해 약 120억 원에 달하는 GPU 인프라 비용 절감 효과를 거뒀다.

솔라 오픈은 미국 비영리 연구기관 에포크AI의 ‘주목할 만한 AI 모델(Notable AI Models)’ 리스트에 이름을 올렸다.

업스테이지는 컨소시엄 정예팀으로 참여중인 ▲노타 ▲래블업 ▲플리토 ▲한국과학기술원(KAIST) ▲서강대학교 등과 기술력을 결집했으며, 앞으로 ‘AI로 여는 일의 표준’을 목표로 산업별 특화 서비스 개발에 박차를 가할 예정이다.

▲금융결제원(금융) ▲로앤컴퍼니(법률) ▲마키나락스(국방·제조) ▲뷰노(의료) ▲오케스트로(공공) ▲데이원컴퍼니(교육) 등 각...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205314)

---

### [신년기획④] 발전소는 서부에, 일자리는 동부에

> 📅 **2026-01-06** | **📌 일반** | 기타 | AI타임스
> 🏷️ 기타

**💡 요약**
[신년기획④] 발전소는 서부에, 일자리는 동부에

<details>
<summary><b>📄 원문 보기</b></summary>

요즘 전남에서는 '해상풍력'이라는 말을 자주 듣는다. 바다 위에 커다란 바람개비(풍력발전기)를 세워 전기를 만드는 것이다. 그런데 여기서 한 가지 질문이 생긴다. "풍력발전기는 서부 바다에 많은데, 그럼 일자리도 다 서부로 가는 걸까?"

광양 스마트항 (AI타임스DB)

꼭 그렇지는 않다. 발전소가 있는 곳과, 일자리가 생기는 곳은 다를 수 있다. 해상풍력은 '발전기'보다 '과정'이 더 크다.

해상풍력은 바람개비 하나 세우는 사업이 아니다. 하나의 풍력단지가 만들어지기까지 여러 과정이 필요하다. ▸커다란 부품을 만든다, ▸항구로 옮긴다, ▸배에 실어 바다로 나간다, ▸설치한다, ▸수십 년 동안 고치고 관리한다.

이 중에서 발전기가 돌아가는 시간보다, 만들고 옮기고 고치는 시간이 훨씬 길다. 즉, 해상풍력의 진짜 일자리는 '제조·운송·정비'에 있다.

이 일자리는 어디에서 생길까? 바다 한가운데에서는 사람이 살 수도, 공장을 지을 수도 없다. 그래서 해상풍력에는 반드시 항구(항만)가 필요하다.

큰 부품을 내리고, 배를 정박시키고, 정비 인력을 출발시키는 곳. 이걸 '지원항만'이라고 부른다. 쉽게 말해, 해상풍력의 본부이자 작업장이다.

지금 전남의 현실은 '지원항만'이 부족하다. 전문가들과 산업계는 "해상풍력을 할 항만이 부족하다"는 이 한가지를 계속 지적한다.

풍력발전기 부품은 아주 크고 무겁다. 일반 항구에서는 못 다룬다 전용 부두와 넓은 땅이 필요하다. 그래서 지금은 몇몇 항만에만 일이 몰릴 가능성이 크다.

여기서 "동부권 항만은 이 역할을 준비하고 있는가?"라는 중요한 질문이 나온다. 동부권 항만이 가진 강점이 필요할 때다.

여수·광양항을 떠올려 보자. 이미 큰 배가 드나든다. 산업단지와 가깝다. 조선·기계·철강 기술이 있다. 이건 해상풍력에 아주 잘 맞는 조건이다. 특히 중요한 점은 이것이다. 해상풍력은 설치보다 정비(MRO)가 더 오래 간다.

20~30년 동안 계속 고치고 관리해야 한다. 즉, 한 번 만들고 끝나는 일이 아니라, 계속 사람이 필요한 산업이다. 이 일자리를 동부권이 가져올 수 있다.

여수는 항만과 산단이 같이 결합된 곳이다. (사진=여수산단/AI타임스DB)

"발전은 서부, 산업은 동부"라는 전략 가능

이제 그림이 보인다. 서부권은 바람이 좋고, 발전에 유리하다. 반면에 동부권은 항만·산업·인력이 있다. 그래서 가능한 전략이 있다.

발전소는 서부에 두고, 관련 산업과 일자리는 동부로 가져오는 것이다. 이건 경쟁이 아니라 역할 나누기다. 서부와 동부가 서로 다른 강점을 살리는 방식이다.

해상풍력만이 아니라 수소·암모니아도 같다. 앞으로 바다를 통해 들어오거나 나갈 에너지는 더 늘어난다.

▸수소 ▸암모니아 ▸새로운 연료들. 이 에너지도 저장할 곳, 옮길 곳, 관리할 곳, 이 모두가 항만과 산업단지에서 이뤄진다. 즉, 동부권 항만은 미래 에너지의 '관문'이 될 수 있다.

그래서 시민의 눈높이에서, 동부권 항만 중 해상풍력 전용으로 쓸 곳은 어디인가? 큰 부품을 놓을 땅은 확보돼 있는가? 이 일을...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205309)

---

### 기업 AI 도입의 핵심으로 떠오른 '통합 온톨로지'란

> 📅 **2026-01-06** | **📌 일반** | 기타 | AI타임스
> 🏷️ LLM, 추론 AI, 에이전트

**💡 요약**
[1월5일] 기업 AI 도입의 핵심으로 떠오른 '통합 온톨로지'란

<details>
<summary><b>📄 원문 보기</b></summary>

기업에서는 부서와 업무에 따라 사용하는 단어에 의미와 범위의 차이가 있습니다. 예를 들어, '고객'은 말은 CRM(고객 관리 시스템)에서는 이름과 이메일, 구매 내역 등으로 정의합니다. 하지만, ERP(재무 관리 시스템)에서는 송장 번호나 미수금, 계약 일자로 표현됩니다. 운영 시스템에서는 배송 주소, 서비스 요청 티켓 번호 등으로 대표됩니다.

이처럼 각 시스템이 '고객'이라는 같은 단어를 쓰지만, 그 정의와 내용은 다릅니다. 언어모델이 이런 뉘앙스와 의미의 차이를 스스로 이해하기란 불가능합니다. 이 때문에 AI를 사용할 때는 원하지 않는 결과가 나오거나, 맥락이 부족하다는 지적이 나옵니다.

따라서 기업 내의 많은 정보를 합치고 싶을 때마다 사람이 복잡하고 오류가 많은 작업을 수동으로 지정해야 합니다. 부서마다 다른 말을 쓰는 것과 같다는 의미에서 이는 '바벨탑'에도 비유됩니다.

여기에서 등장하는 것이 '온톨로지(Ontology)'입니다. 온톨로지란 '존재에 대한 연구'라는 철학적 개념으로, 컴퓨터 과학에서는 특정 분야의 지식(개념, 개체, 속성, 관계 등)을 컴퓨터가 이해하고 처리할 수 있도록 명확하게 정의하고 구조화한 지식 모델을 말합니다.

온톨로지는 지난해부터 개념 간의 관계와 지식의 구조를 표현하는 '지식 그래프(Knowledge Graph)'의 개념으로 종종 소개됐지만, 최근 본격적으로 부각되고 있습니다.

특히, 기업 고객과 자산, 정책, 이벤트 등과 그 관계에 대한 공유 모델을 의미하는 통합 온톨로지(Integrated Ontology)가 강조됩니다. 이는 기업 온톨로지(Enterprise Ontology)라고도 불립니다.

이는 AI가 인간 대신 업무를 처리하는 에이전트 단계로 진입했기 때문입니다. 이전에는 직원들이 개별적으로 챗봇과 소통하면서 개념을 발전할 수 있었지만, 이제는 에이전트가 일을 대신해야 하므로 온톨로지 통합이 없이는 맥락 문제를 자주 겪을 수밖에 없습니다.

알렉스 카프 팔란티어 CEO

도 이미 2024년 6월 "시장의 모든 가치가 칩과 우리가 온톨로지라고 부르는 것에 집중될 것"이라며 "온톨로지는 AI의 힘을 현실 세계의 사물과 관계에 연결하는 것"이라고 밝힌 바 있습니다.

통합 온톨로지는 전사적으로 통일된 하나의 '공용 지도'나 '공통 언어'를 만들자는 것입니다.

여기에는 ▲'고객' '제품' '공급업체' '계약' '이벤트' 같은 핵심 항목들을 전사적으로 하나의 정의로 통일하는 객체(명사) 통합 ▲'고객이 구매하다' '계약이 연결되다' '제품이 포함되다'와 같은 객체 간의 연결 방식을 통일하는 관계(동사) 통합이 포함됩니다.

이를 통해 온톨로지가 연결되고 통합되면 에이전트는 단일 앱을 넘어 기업 활동 전반에서 추론하고 행동할 수 있게 된다는 것입니다. 예를 들어, 에이전트는 '재고가 부족한 특정 고객의 주문 건에 대해, 계약 일자가 긴 공급업체 A 대신 공급업체 B를 통해 긴급 배송을 자동 승인하라'는 식의 복합적인 의사결정을 오류 없이 수행할 수 있습니다.

브라이언 멀콘레이 슈어리파이...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205286)

---

### ﻿"모바일·TV·가전에 AI 통합"... 삼성전자, CES서 'AI 대중화' 비전 공개

> 📅 **2026-01-06** | **📌 일반** | Google | AI타임스
> 🏷️ 멀티모달, 로보틱스, 음성/오디오

**💡 요약**
﻿"모바일·TV·가전에 AI 통합"... 삼성전자, CES서 'AI 대중화' 비전 공개

<details>
<summary><b>📄 원문 보기</b></summary>

노태문 삼성전자 대표이사 사장(DX부문장) (사진=삼성전자)

삼성전자가 미국 라스베이거스에서 열리는 'CES 2026'에 앞서 '더 퍼스트 룩(The First Look)' 프레스 컨퍼런스에서 AI 비전과 전략을 발표했다고 5일(현지시간) 밝혔다.

전 세계 미디어와 파트너 등 1500여명이 참석한 가운데 삼성전자는 '당신의 AI 일상 동반자(Your Companion to AI Living)'를 주제로 ▲엔터테인먼트 컴패니언 ▲홈 컴패니언 ▲케어 컴패니언 비전과 이를 구현하는 신제품·신기술을 대거 공개했다.

구체적으로는 ▲기업과 협업을 통한 고객 선택권 확대 ▲온디바이스 AI와 클라우드 결합을 통한 서비스 최적화 ▲스마트싱스·원 UI·나우 브리프 등 AI 인터페이스 강화 ▲삼성 녹스 기반 강력한 보안과 AI 신뢰도 강화를 소개했다. 컨퍼런스에서 발표된 제품과 서비스는 윈 호텔에 마련된 삼성전자 전용 전시관에서 확인 가능하다.

■'비전 AI 컴패니언' 플랫폼 탑재...TV·디스플레이 혁신

삼성전자는 최신 AI 기술과 디스플레이 기술력이 결합된 삼성 TV 전용 AI 플랫폼 '비전 AI 컴패니언(Vision AI Companion)'을 선보였다.

비전 AI 컴패니언은 고도화된 AI 기술로 사용자의 질문 맥락을 이해하고 최적화된 인사이트를 제공하며 상호작용한다.

올해 TV 라인업에는 화질·음질 관련최신 기술도 적용됐다. 업계 최초 차세대 HDR 표준인 'HDR10+ 어드밴스드'와 구글과 공동 개발한 '이클립사 오디오', '큐 심포니(Q-Symphony)' 등이 탑재돼 차별화된 화질과 사운드 몰입감을 제공한다는 설명이다.

또 자체 TV OS인 타이젠 OS에 대해 7년 동안 업그레이드를 지원해 사용자의 라이프스타일에 맞춰 함께 진화해나간다는 계획이다. 이외 세계 최초 130형 '마이크로 RGB TV'와 벽걸이 마운트 'OLED TV' 등 신제품도 공개했다.

용석우 삼성전자 영상디스플레이사업부장(사장)은 "삼성전자는 20년간 글로벌 TV 시장 1위 리더십을 바탕으로 혁신적인 기술과 제품을 통해 고객의 일상에 즐거움과 편안함을 선사하며 시장을 선도하겠다"라고 말했다.

용석우 삼성전자 영상디스플레이사업부장(사장) (사진=삼성전자)

■ 집안일 해방 목표 '홈 컴패니언'...가전 최초 '구글 제미나이' 탑재

가전 부문은 4억 명 사용자를 가진 스마트 홈 플랫폼 '스마트싱스' 기반 스크린·카메라·보이스가 결합된 '홈 컴패니언(Home Companion)' 비전을 소개했다.

특히 올해 '비스포크 AI 패밀리허브' 냉장고에는 가전 최초로 구글의 제미나이 모델이 탑재됐다. ▲냉장고 식재료 기반 레시피 추천 ▲요리 영상과 레시피 안내 ▲식재료 사용량 분석과 식생활 리포트 등의 기능을 제공한다.

비스포크 AI 스팀 로봇청소기는 퀄컴 칩셋과 RGB 카메라·듀얼 카메라로 구성된 3D 장애물 센서로 가구 등 사물뿐만 아니라 투명한 액체까지 인식한다.

비스포크 AI 에어드레서와 AI 콤보에서도 세탁·건조부터 의류 관리까지 일관된 경험을 제공한다는...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205313)

---

### 차세대 AI PC를 위한 프로세서 '인텔 코어 Ultra 시리즈 3' 출시

> 📅 **2026-01-06** | **📌 일반** | NVIDIA | 인공지능신문
> 🏷️ LLM, 멀티모달, 로보틱스

**💡 요약**
차세대 AI PC를 위한 프로세서 '인텔 코어 Ultra 시리즈 3' 출시

<details>
<summary><b>📄 원문 보기</b></summary>

인텔 코어 Ultra 시리즈 3 프로세서

인텔은 CES 2026에서 미국에서 설계·제조된 인텔 18A 공정 기술을 기반으로 한 최초의 인공지능(AI) PC 플랫폼 '인텔 코어 울트라 시리즈3(Intel® Core™ Ultra Series 3)' 프로세서를 공개했다. 해당 프로세서는 글로벌 주요 파트너사의 200개 이상 제품 설계에 탑재되며, 인텔이 지금까지 선보인 AI PC 플랫폼 가운데 가장 폭넓게 글로벌 시장에 공급되는 플랫폼이 될 전망이다.

인텔 클라이언트 컴퓨팅 그룹 총괄 짐 존슨(Jim Johnson) 부사장은 “이번 인텔 코어 Ultra 시리즈 3를 통해 전력 효율과 CPU 성능을 한층 강화하고, 동급 최고 수준의 GPU와 개선된 AI 연산 성능을 제공한다”며, “x86 아키텍처 기반에서 신뢰할 수 있는 애플리케이션 호환성 역시 강화했다”고 말했다.

인텔 코어 Ultra 시리즈 3 모바일(노트북) 라인업에는 최고 성능의 통합형 인텔 아크(Arc™) 그래픽을 탑재한 새로운 등급의 인텔 코어 Ultra X9 및 X7 프로세서가 포함된다. 이들 프로세서는 이동 중에도 게이밍, 콘텐츠 제작, 생산성 등 고급 워크로드를 동시에 처리하는 멀티태스킹을 위해 설계됐다. 최상위 SKU는 최대 16개 CPU 코어, 12개 Xe 코어, 50 NPU TOPS를 제공하며, 멀티스레드 성능은 최대 60% 향상, 게이밍 성능은 최대 77% 이상 개선됐고, 최대 27시간 지속되는 배터리 수명을 목표로 설계됐다.

인텔 코어 Ultra 시리즈 3 제품군에는 메인스트림 급 노트북 구동을 위해 설계된 인텔 코어 프로세서도 포함하고 있다. 인텔 코어 Ultra 시리즈 3과 동일한 기본 아키텍처를 활용하는 인텔 코어 라인업은 더 저렴한 가격대에서 가성비와 효율성을 갖춘 노트북 설계를 가능하게 한다.

로보틱스·스마트 시티·자동화·헬스케어 분야의 AI 도입 가속화

시리즈 3 엣지 프로세서는 PC 버전과 더불어 최초로 임베디드 및 산업용 인증을 획득했다. 이를 통해 확장된 작동 온도 범위, 성능, 그리고 24시간 상시 가동이 가능한 신뢰성 등 산업 현장의 까다로운 요건을 충족한다.

인텔 코어 Ultra 시리즈 3는 핵심 엣지 AI 워크로드에서 경쟁력을 제공하며, 대규모 언어 모델(LLM) 성능은 최대 1.9배 향상⁴, 엔드투엔드 비디오 분석에서는 와트·달러당 성능이 최대 2.3배 개선⁵, 비전-언어-액션(VLA) 모델 처리량은 최대 4.5배 향상⁶됐다. 또한 통합형 AI 가속을 통해 기존의 멀티칩 CPU·GPU 아키텍처 대비 단일 시스템온칩(SoC) 솔루션으로 더 우수한 총소유비용(TCO)을 제공한다.

인텔 코어 Ultra 시리즈 3 프로세서를 탑재한 최초의 소비자용 노트북은 6일부터 사전 예약할 수 있다. 해당 제품은 2026년 1월 27일부터 전 세계 시장에서 판매될 예정이며, 추가 제품들은 2026년 상반기 동안 순차적으로 공개된다. 인텔 코어 Ultra 시리즈 3 기반의 엣지 시스템은 2026년 2분기부터 출시될 예정이다.

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38009)

---

### 엔비디아 젠슨 황, “로보틱스 분야에도 ‘챗GPT 시대’가 도래했다

> 📅 **2026-01-06** | **📌 일반** | Microsoft | 인공지능신문
> 🏷️ LLM, 추론 AI, 에이전트

**💡 요약**
엔비디아 젠슨 황, “로보틱스 분야에도 ‘챗GPT 시대’가 도래했다

<details>
<summary><b>📄 원문 보기</b></summary>

젠슨 황 CEO의 기조연설 모습

엔비디아가 미국 라스베이거스에서 열린 세계 최대 IT·가전 전시회 CES 2026에서 피지컬 AI를 위한 새로운 오픈 모델, 프레임워크, AI 인프라를 발표하고, 글로벌 파트너들과 협력해 다양한 산업용 로봇을 5일(현지시간) 공개했다.

새롭게 공개된 엔비디아 기술은 로봇 개발 전반의 워크플로우를 가속화해, 다양한 작업을 빠르게 학습할 수 있는 전문가형 범용(generalist-specialist) 로봇을 포함한 차세대 로보틱스의 확산을 촉진한다.

보스턴 다이내믹스(Boston Dynamics), 캐터필러(Caterpillar), 프랑카 로보틱스(Franka Robots), 휴머노이드(Humanoid), LG전자(LG Electronics), 뉴라 로보틱스(NEURA Robotics) 등 글로벌 산업 선도 기업들은 엔비디아 로보틱스 스택을 활용한 새로운 AI 기반 로봇을 공개했다.

엔비디아 창립자 겸 CEO 젠슨 황(Jensen Huang)은 “로보틱스 분야에도 ‘챗GPT 시대’가 도래했다. 현실 세계를 이해하고, 추론하며, 행동을 계획하는 피지컬 AI 모델의 도약은 완전히 새로운 애플리케이션을 가능하게 한다. 엔비디아의 젯슨(Jetson) 로보틱스 프로세서, 쿠다(CUDA), 옴니버스(Omniverse), 오픈 피지컬 AI 모델로 구성된 풀스택은 글로벌 파트너 생태계가 AI 기반 로보틱스를 통해 산업을 혁신할 수 있도록 지원한다”고 말했다.

새로운 오픈 모델, 로봇 학습과 추론 고도화

현재의 고비용, 단일 작업 중심의 프로그래밍이 까다로운 기계들을 추론 가능한 ‘전문가형 범용’ 로봇으로 전환하려면, 파운데이션 모델 구축을 위한 막대한 자본과 전문 지식이 필요하다.

엔비디아는 개발자가 자원 집약적인 사전 훈련을 생략하고, 차세대 AI 로봇과 자율형 머신 개발에 집중할 수 있도록 지원하는 오픈 모델을 구축하고 있다.

▷물리 기반 합성 데이터 생성과 시뮬레이션 환경에서의 로봇 정책 평가를 지원하는 완전 맞춤형 오픈 월드 모델 '엔비디아 코스모스™ 트랜스퍼 2.5(Cosmos™ Transfer 2.5-

▷엔비디아 코스모스 프리딕트 2.5(Cosmos Predict 2.5-

)', 지능형 머신이 인간처럼 현실 세계를 인식하고, 이해하며 행동할 수 있도록 지원하는 오픈 추론 비전 언어 모델(vision language model, VLM) '엔비디아 코스모스 리즌 2(Cosmos Reason 2-

▷엔비디아 코스모스 리즌을 활용해 향상된 추론과 컨텍스트 이해를 지원하며, 전신 제어를 가능하게 하는 휴머노이드 로봇에 특화된 오픈 추론 VLA 모델 '엔비디아 아이작™ GR00T N1.6(Isaac™ GR00T N1.6-

)' 등 새로운 모델이 깃허브 및 허깅 페이스(Hugging Face)를 통해 제공된다.

프랑카 로보틱스, 뉴라 로보틱스, 휴머노이드는 GR00T 기반 워크플로우를 활용해 로봇의 새로운 동작을 시뮬레이션, 훈련, 검증하고 있다. 세일즈포스(Salesforce)는 에이전트포스(Age...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38008)

---

### SK AX ‘생성형AI 활용 자격증’ 국내 첫 정부공인…산업 AI전환 가속 돕는다

> 📅 **2026-01-06** | **📌 일반** | 기타 | 인공지능신문
> 🏷️ 에이전트

**💡 요약**
SK AX ‘생성형AI 활용 자격증’ 국내 첫 정부공인…산업 AI전환 가속 돕는다

<details>
<summary><b>📄 원문 보기</b></summary>

사진:AI 생성이미지

산업현장의 AI 전환을 선도하는 SK AX(사장 김완종)가 개발한 ‘AI 역량 인증 플랫폼’이 국내 생성형 AI 분야 역량 인증 체계로는 처음으로 정부공인을 받았다. 조직 전반의 인공지능 활용 역량을 높이는 것이 기업들의 숙제로 떠오른 만큼, SK AX의 인증제는 국내 산업의 AI 전환 가속에 도움이 될 것으로 기대된다.

SK AX는 ‘AI 역량 인증 플랫폼’으로 고용노동부와 한국산업인력공단의 ‘기업자격 정부인정제’ 사업주 자격을 획득했다고 6일 밝혔다. 작년부터 SK그룹 구성원 약 3800명을 대상으로 운영해온 생성형 AI 활용 역량 인증 플랫폼과 운영 제도가 정부로부터 업무 생산성 제고 효과와 객관성을 인정받은 것이다.

SK AX 측은 “이번 인증제가, 다양한 산업에 종사하는 실무자들이 생성형 AI를 제대로 활용할 수 있는지를 체계적으로 측정·검증할 수 있는 제도임을 평가받았다는 점에서 의미가 크다”고 설명했다. 이미 국내 산업계에서 AI 역량 인증 플랫폼 도입을 결정하는 등 산업 전반으로의 확산 가능성도 확인되고 있다.

‘기업자격 정부인정제’는 기업이 자체 운영하는 직무 자격제도에 대해 한국산업인력공단이 평가 체계 완성도와 평가 결과의 객관성, 운영 성과 등을 종합적으로 심사해 공신력을 부여하는 제도다. SK AX는 시험 응시부터 채점·평가까지 전 과정을 AI를 활용해 자동화하고, 실제 업무 수행 역량을 검증하는 독창적 구조를 갖췄다는 점에서 높은 평가를 받았다.

특히 SK AX는 단순히 ‘AI를 배웠는가’를 넘어 ‘AI로 일을 바꿀 수 있는가’를 검증하는 방식으로 기존 자격 제도와 차별화를 꾀했다. 시험은 사업기획, 소프트웨어 개발, 시장조사, 인사전략 등 실제 직무 상황을 기반으로 생성형 AI를 활용해 문제를 해결하도록 설계돼 있으며, 보고서·스프레드시트·소스코드·다이어그램 등 현업에서 바로 쓰이는 결과물로 평가가 이뤄진다.

인증 과정은 두 단계로 나뉜다. 첫 단계인 ‘AI 리터러시(Literacy)’는 생성형 AI의 기본 원리 이해부터 프롬프트 활용, 일상 업무 적용 능력을 검증한다. 구성원은 온라인 플랫폼을 통해 학습과 시험에 참여하고, 실제 업무 맥락에서 AI 문해력과 실행력을 평가받는다.

다음 단계인 ‘AI 부트캠프(Boot Camp)’에서는 한층 높은 수준의 AI 활용 역량을 검증한다. 검색증강생성(RAG) 기반 시스템, AI 기능이 적용된 웹·앱 개발 등 실습 중심 교육을 거쳐, AI 에이전트 서비스를 직접 설계·개발하고 결과물에 대한 기술 평가를 통해 인증을 받는다.

모든 과정은 교육, 실습, 평가, 채점까지 AI 기반 온라인 플랫폼에서 운영돼, 대규모 조직에서도 활용할 수 있도록 설계됐다.

SK AX 김민환 HRX추진담당은 “AI 전환은 이제 특정 부서나 전문가의 영역이 아니라 모든 구성원의 역량 내재화와 변화관리를 필요로 한다” 며 “이번 정부인정 획득은 SK AX가 실제 산업 현장에서 검증한 AI 교육·인증 모델이 공신력을 확보했다는 의미로, 앞으로 AI 전환을 추진하는 기...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38007)

---

### 퀄컴, ‘피지컬 AI’ 전면전 선언…가정용 로봇부터 휴머노이드까지 아우르는 로보틱스 풀스택 공개

> 📅 **2026-01-06** | **📌 일반** | 기타 | 인공지능신문
> 🏷️ 추론 AI, 멀티모달, 로보틱스

**💡 요약**
퀄컴, ‘피지컬 AI’ 전면전 선언…가정용 로봇부터 휴머노이드까지 아우르는 로보틱스 풀스택 공개

<details>
<summary><b>📄 원문 보기</b></summary>

사진:퀄컴

퀄컴 테크놀로지스(Qualcomm Technologies)가 가정용 로봇부터 산업용 자율이동로봇(AMR), 풀사이즈 인공지능(AI) 휴머노이드에 이르기까지 폭넓게 적용 가능한 차세대 로보틱스 기술 포트폴리오를 공개했다.

퀄컴은 현지시간 5일 미국 라스베이거스에서 열린 CES 2026에서 하드웨어·소프트웨어·복합 AI를 통합한 차세대 범용 로보틱스 풀스택 아키텍처와 함께, 최신 프리미엄급 로봇 프로세서인 ‘퀄컴 드래곤윙(Dragonwing) IQ10 시리즈’를 선보였다.

이번에 공개된 로보틱스 아키텍처는 안전 등급의 고성능 SoC 플랫폼을 기반으로 높은 전력 효율과 확장성을 동시에 구현한 것이 특징이다. 개인 서비스 로봇부터 차세대 산업용 자율이동로봇(AMR), 추론·적응·의사결정이 가능한 휴머노이드 로봇까지 폭넓은 폼팩터를 지원하며, 지속적으로 학습하는 범용 로봇 구현을 목표로 한다.

퀄컴은 해당 아키텍처를 통해 리테일, 물류, 제조 분야에서 범용 로봇의 자동화를 가속화하고, 실험실 단계에 머물던 로봇 기술을 실제 산업 환경에 빠르게 적용한다는 전략이다. 특히 드래곤윙 IQ10 시리즈는 휴머노이드와 고급 AMR을 겨냥한 로봇 전용 프로세서로, ‘로봇의 두뇌(Brain of the Robot)’ 역할을 수행하도록 설계됐다.

나쿨 두갈(Nakul Duggal) 퀄컴 테크놀로지스 자동차·산업·임베디드 IoT 및 로보틱스 부문 총괄 부사장은 “에너지 효율적이면서도 고성능의 피지컬 AI 시스템을 구현하기 위해서는 센싱, 인지, 계획, 행동에 이르는 저지연·고신뢰 기술이 필수적”이라며 “이번 로보틱스 아키텍처는 지능형 기계를 연구실 밖 실제 환경으로 확장하는 전환점이 될 것”이라고 강조했다.

퀄컴은 휴머노이드 로봇 기업 피겨(Figure)와 차세대 컴퓨트 아키텍처 공동 정의를 위한 협력도 진행 중이다. 브렛 애드콕(Brett Adcock) 피겨 CEO는 “퀄컴의 고성능·고효율 컴퓨팅 플랫폼은 범용 휴머노이드 비전을 현실로 구현하는 데 핵심적인 기반 기술”이라고 평가했다.

이와 함께 퀄컴은 어드밴텍, 쿠카 로보틱스(KUKA Robotics), 로보텍.ai, 빈모션(VinMotion) 등 다양한 글로벌 파트너와 협력해 대규모 상용 배포가 가능한 로봇 생태계 구축에도 나서고 있다. 드래곤윙 산업용 프로세서 로드맵은 이미 다수의 휴머노이드 및 범용 로봇 플랫폼에 적용되고 있으며, 향후 산업 현장 중심의 실질적인 피지컬 AI 확산을 가속화할 것으로 기대된다.

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38005)

---

### "딥시크의 mHC, LLM 학습 통념 깼지만 실제 구현은 난제"

> 📅 **2026-01-06** | **📌 일반** | Microsoft | AI타임스
> 🏷️ LLM

**💡 요약**
"딥시크의 mHC, LLM 학습 통념 깼지만 실제 구현은 난제"

<details>
<summary><b>📄 원문 보기</b></summary>

기사를 읽어드립니다.

딥시크가 대형언어모델(LLM) 학습 방식을 근본적으로 바꿀 수 있는 새로운 신경망 아키텍처를 제안한 가운데, 이에 대한 호평이 이어지고 있다. 동시에, 실제 적용까지는 넘어야 할 기술적 과제도 적지 않다는 지적이 나왔다.

딥시크는 지난주 공개한 기술 논문에서 mHC(Manifold-Constrained Hyper-Connections)라는 새로운 구조를 제안했다.

mHC는 바이트댄스가 2024년 제안한 하이퍼 커넥션(HC) 구조의 학습 불안정성을 해결하기 위해 고안됐다. HC는 다수의 최신 딥러닝 모델의 기반인 잔차 신경망(ResNet)의 한계를 극복하기 위한 시도로, 정보 흐름을 단일 경로가 아닌 다중 경로로 확장한 것이 특징이다.

ResNet은 약 10년 전 마이크로소프트 리서치 아시아의 허카이밍 연구진이 제안한 구조로, 오늘날 LLM을 포함한 수많은 모델의 뼈대 역할을 해왔다. 그러나 HC 구조는 경로가 늘어나는 만큼 학습이 불안정해지고, 극단적인 경우에는 학습이 붕괴는 문제가 있었다.

이에 대해 송린치 홍콩시립대학교 교수는 사우스차이나모닝포스트와의 인터뷰에서 “딥시크다운 연구”라고 평가했다.

그는 ResNet을 “정보가 흐르는 단일 차선”으로, HC를 “여러 차선이 있는 고속도로”에 비유했다. mHC는 이 차선들에 명확한 규칙을 부여해 정보 흐름이 무너지지 않도록 제어한다는 설명이다. 추가 계산 부담 없이 안정성을 확보했다는 점에서 “더 강력하고 신뢰할 수 있는 모델로 가는 실질적인 경로”라는 호평했다.

궈쑹 홍콩과학기술대학교 교수는 이번 연구가 LLM 연구의 방향 전환을 시사한다고 봤다. 지금까지는 미세한 구조 조정 같은 ‘마이크로 디자인’이 주류였다면, mHC가 지향하는 알고리즘-하드웨어 공동 설계 및 메모리와 연산의 분리는 LLM 연구의 '매크로 디자인' 전환이라는 것이다.

그는 특히 “ResNet이라는 백본은 건드릴 수 없다는 통념을 깼다”라며, 앞으로 알고리즘과 하드웨어 공동 설계, 그리고 메모리 용량과 연산의 분리(decoupling)가 효율적 확장의 핵심이 될 수 있다고 전망했다.

하지만, 신중론도 만만치 않다. 송 교수는 mHC가 현재까지는 4개 경로, 최대 270억 매개변수 모델까지 검증됐지만, 수백억~수천억 매개변수 규모의 최첨단 모델에서도 동일한 효과를 낼지는 미지수라고 지적했다.

궈 교수도 “프론티어 모델에서도 효용성이 있을지는 미지수”라고 말했다. 예디얀 영 홍콩과기대 교수도 ResNet처럼 판도를 바꿀 잠재력은 인정하면서도, 다양한 아키텍처 전반에서 검증되기 전까지는 성급한 결론을 경계해야 한다고 덧붙였다.

구현 난이도도 난제로 꼽혔다. 궈 교수는 mHC가 최첨단 인프라에 의존할 가능성이 있어, 소규모 연구실이나 모바일 환경에서는 도입 장벽이 될 수 있다고 지적했다.

그런데도 업계의 기대감은 크다는 평이다. 송 교수는 이번 연구를 “바퀴의 발견”에 비유하며, 안정적인 새로운 기반이 열릴 경우 연구자와 엔지니어들이 앞다퉈 바퀴를 교체하려 할 것이라고 말했다.

실제...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205344)

---

### 오픈AI 추론 모델 이끈 연구 책임자 퇴사...'IMO 금메달 모델' 개발 끝났나

> 📅 **2026-01-06** | **📌 일반** | OpenAI | AI타임스
> 🏷️ LLM, 추론 AI, 강화학습

**💡 요약**
오픈AI 추론 모델 이끈 연구 책임자 퇴사...'IMO 금메달 모델' 개발 끝났나

<details>
<summary><b>📄 원문 보기</b></summary>

기사를 읽어드립니다.

오픈AI의 저명한 연구자인 제리 트워렉이 7년 만에 퇴사한다. "새로운 연구를 위한 것"이라는 이유인데, 이에 따라 그가 주도하던 새로운 모델 프로젝트가 마무리된 것이라는 예측이 가능해진다.

트워렉 오픈AI 연구 부사장은 6일(현지시간) X(트위터)를 통해 퇴사 소식을 알렸다. 그는 "오픈AI에서 하기 어려운 연구 유형을 탐구하기 위해 떠난다"라고 밝혔다.

2019년 오픈AI에 입사, 2022년부터 연구팀 리드를 맡았다. 이 과정에서 '챗GPT'와 'GPT-4'에 이어 첫 추론 모델 'o1'까지 주요 제품군의 개발을 이끌었다. 또 입사 초기에는 로봇을 통한 강화 학습(RL) 연구에 참여했고, 이후에는 세계 최초의 코딩 모델을 개발한 경력도 가지고 있다.

앞으로의 계획을 구체적으로 밝히지는 않았으나, 오픈AI에 대해서는 칭찬을 아끼지 않았다. 문제가 생겨서 떠나는 것이 아니라는 것이다.

그는 "나는 세계에서 가장 강력한 ML 팀을 구성하고 성장시킬 수 있는 특권을 누렸다"라며 "이곳은 특별한 회사이자 인류 역사에 영원히 남을 특별한 곳"이라고 말했다.

또 그의 글에는 로건 킬패트릭 구글 AI 스튜디오 제품 총괄과 노엄 브라운 오픈AI 수석 연구원, 윌리엄 페두스 피어리오딕 랩스 창립자, 네이선 램버트 연구원 등 유명한 동료들이 새로운 출발을 축하했다.

This is the note I have shared with my team today:

pic.twitter.com/qvClP6MQQy

— Jerry Tworek (@MillionInt)

January 5, 2026

특히, 트워렉 부사장은 지난 11월 X를 통해 국제수학올림피아드(IMO) 금메달 모델에 대한 소식을 전한 바 있다. 당시 게리 마커스 뉴욕대학교 교수가 IMO 금메달 소식 이후 거의 반년이 지났지만, 아직 모델이 출시되지 않았다고 지적한 데 따른 것이다.

앞서 샘 알트먼 오픈AI CEO는 9월 "앞으로 몇주 안에 새로운 컴퓨팅 집약적 서비스를 출시할 예정"이라고 예고했으며, 이에 따라 범용 검증기(Universial Verifier)'를 탑재한 고급 추론 모델이 등장할 것으로 예측됐다. 그러나 11월이 되도록 모델이 나오지 않자, 마커스 교수는 "미공개 모델이 현재 공개된 최고의 모델(GPT-5 프로)보다 확실히 뛰어나다는 것은 추측에 불과하며 아마도 틀렸을 것"이라고 비판했다.

그러자 트워렉 부사장은 댓글을 통해 "걱정하지 말라"라며 "연구 프로토타입을 완성해서 공개하려면 많은 노력과 시간이 필요하지만, 훨씬 개선된 IMO 모델이 앞으로 몇달 안에 출시될 예정"이라고 밝혔다.

또 이 모델이 "GPT 5.x를 전면적으로 대체할 것인가, 아니면 특정 작업에만 사용되는 버전인가"라는 질문에는 "특화 모델은 아니다. 그 때문에 개발에 시간이 오래 걸리는 것"이라고 답했다.

Don’t worry, we’ve got you!

It is indeed a lot of work and takes some time to get research...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205337)

---

### 엔비디아, 자율주행·로봇용 오픈 소스 제품군 '알파마요' 출시

> 📅 **2026-01-06** | **📌 일반** | NVIDIA | AI타임스
> 🏷️ LLM, 추론 AI, 멀티모달

**💡 요약**
엔비디아, 자율주행·로봇용 오픈 소스 제품군 '알파마요' 출시

<details>
<summary><b>📄 원문 보기</b></summary>

기사를 읽어드립니다.

엔비디아가 자율주행차와 로봇을 위한 새로운 오픈 소스 제품군을 공개하며 ‘피지컬 AI’ 시대의 본격 개막을 선언했다.

엔비디아는 5일(현지시간) 미국 라스베이거스에서 열린 CES에서 차량이나 로봇이 실제 환경에서 추론할 수 있도록 설계된 새로운 오픈 소스 자율주행 플랫폼 ‘알파마요(Alpamayo)’를 공개했다.

알파마요는 자율 주행 차량이 복잡한 주행 상황을 추론하는 데 도움을 주기 위해 설계된 로봇과 차량 훈련용 오픈 소스 AI 모델과 시뮬레이션 도구, 데이터셋 제품 등을 통칭하는 새로운 브랜드다.

알파마요 제품군의 핵심은 ‘알파마요 1’이다. 이는 지난해 뉴립스를 통해 처음 공개된 100억(10B) 매개변수 규모의 비전언어행동(VLA) 모델 ‘알파마요-R1’을 상용화해 출시한 것이다.

이 모델은 자율주행차가 사람처럼 사고 과정을 거쳐 판단하도록 설계됐다. 단순히 센서 입력에 반응하는 수준을 넘어, 실제 세계의 복잡한 상황을 이해하고 추론하며 행동까지 설명할 수 있도록 한 것이다.

알리 카니 엔비디아 자동차 부문 부사장은 “알파마요 1은 문제를 단계별로 분해하고, 가능한 모든 선택지를 추론한 뒤 가장 안전한 경로를 선택한다”라고 설명했다. 신호등이 고장 난 복잡한 교차로처럼 기존 학습 데이터에 없는 상황에서도 사전 경험 없이 합리적인 판단을 내릴 수 있다는 것이다.

젠슨 황 CEO는 “알파마요는 센서 입력을 받아 조향·제동·가속을 제어하는 데서 그치지 않고, 어떤 행동을 할지, 왜 그런 결정을 내렸는지, 그리고 그 결과로 어떤 주행 궤적이 나올지를 모두 설명한다”라고 강조했다.

알파마요 1의 핵심 코드는

허깅페이스

를 통해 오픈 소스로 공개됐다. 개발자들은 이를 기반으로 더 작고 빠른 경량 모델로 미세조정하거나, 단순한 주행 시스템 학습에 활용할 수 있다. 또 영상 데이터를 자동으로 라벨링하는 도구나, 차량의 판단이 합리적이었는지를 평가하는 검증 시스템 등 다양한 응용 도구를 구축할 수 있다.

여기에 엔비디아의 월드 모델 브랜드인 ‘코스모스(Cosmos)’와 결합해, 실제 주행 데이터와 합성 데이터를 함께 활용한 학습·테스트도 가능하다. 코스모스는 물리 환경을 가상으로 재현해 미래 상황을 예측하고 행동을 결정할 수 있도록 돕는 AI 시스템이다.

엔비디아는 알파마요 공개와 동시에 1700시간 이상의 주행 데이터를 담은 오픈 데이터셋도 출시했다. 이 데이터는 다양한 지역과 환경에서 수집됐으며, 실제 도로에서 드물게 발생하는 복잡한 시나리오까지 포함하고 있다. 해당 데이터셋은

허깅페이스

에서 이용 가능하다.

또 자율주행 시스템 검증을 위한 오픈 소스 시뮬레이션 프레임워크 ‘알파심(AlpaSim)’을 공개했다.

깃허브

에서 제공되는 알파심은 센서, 교통 상황, 도로 환경 등 현실 세계의 주행 조건을 정밀하게 재현해 대규모 테스트를 안전하게 수행할 수 있도록 설계됐다.

이번 알파마요 공개는 자율주행 AI가 단순한 패턴 인식과 반응형 제어를 넘어, 이해·추론·설명 가능한 판단 단계로 진화하고...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205316)

---

### 애플 출신 로봇 스타트업이 5년 만에 스텔스를 벗어난 이유는

> 📅 **2026-01-06** | **📌 일반** | Microsoft | AI타임스
> 🏷️ 멀티모달, 로보틱스

**💡 요약**
애플 출신 로봇 스타트업이 5년 만에 스텔스를 벗어난 이유는

<details>
<summary><b>📄 원문 보기</b></summary>

유명 3D 센싱 전문가들이 창립한 로봇 스타트업이 무려 5년 만에 스텔스 상태를 벗어나 공식 활동을 시작했다. 이들의 기술은 애플의 '페이스 ID'에 사용됐던 것으로, 이를 통해 로봇의 시각 능력을 극대화한다는 것이다.

라이트(Lyte)는 5일(현지시간) 투자 유치를 확정하고 공식 출범한다고 발표했다. "로봇이 물리 세계를 보고 이해하고 안전하게 작동할 수 있도록 하는 것"이 목표라고 밝혔다.

이들은 4년 동안 피델리티와 어트레이디즈, 엑소르, 키1 등 투자자들로부터 누적 1억700만달러를 유치했다. 직원은 벌써 100명에 달하며, 대표 제품도 개발한 상태다.

라이트는 애플의 얼굴 인식 기술인 페이스 ID 개발 주역 3명이 2021년 설립했다. 페이스 ID는 사용자 얼굴을 3D로 인식해 기기 잠금 해제, 앱 로그인, 애플페이 인증 등에 활용하는 안면 인식 기술이다. 특히, 100만분의 1 수준의 뛰어난 보안성으로 호평받았다.

이들은 'CES 2026'를 계기로 공식 활동을 선언했다. 지난해 출품한 '라이트 비전(LyteVision)'이라는 제품으로 '로보틱스 부문 최고 혁신상'과 '차량 기술 및 첨단 모빌리티 부문 혁신상'을 수상하며 주목받았다.

이번 행사에서도 기술 노출을 줄이기 위해 대형 전시 부스를 차리는 대신, 예약 시연 위주로 기술을 선보이고 있다.

라이트 비전은 로봇이 물리적 세상을 이해하고 안전하게 작동할 수 있도록 돕는 통합 센싱 플랫폼이다. 카메라에 주로 의존하는 기존 로봇과는 달리, 카메라와 관성 모션 센서, 거리와 속도를 측정하는 4D 센서 등 세가지 유형의 센서가 포함돼 있다. 이를 통해 위치 데이터와 시각 데이터를 하나의 플랫폼에 통합해 수집, 로봇의 눈과 시각 피질(인지) 역할을 동시에 수행하는 '시각 두뇌(Visual Brain)' 역할을 한다는 것이다.

라이트 비전 (사진=라이트)

알렉산더 슈푼트 창립자는 블룸버그와의 인터뷰에서 이 기술의 목표가 "좀비 로봇이 되지 않는 것"이라고 밝혔다. 이는 현재의 로봇 기술이 인지 오류나 안전 문제로 인해 예상치 못한 행동을 하거나 동작을 중단하는 한계를 해결하기 위해 즉시 활용한 데이터를 공급하겠다는 것으로, 로봇 상용화의 근본적인 문제인 안전성과 신뢰성을 해결하겠다는 의도다. 또, 이 기술은 휴머노이드 로봇과 로보택시 등 다양한 분야에 적용할 수 있다고 덧붙였다.

맞춤형 칩과 광학 부품, 소프트웨어 등을 직접 개발 중이다. 로봇 업계의 주요 과제 중 하나는 센서 통합 과정이 매우 길어 제품 출시까지 수년이 걸릴 수 있다는 점이며, 라이트는 센서와 구성 요소가 하나의 플랫폼에 내장한 플러그 앤 플레이 솔루션으로 이 문제를 해결하겠다는 것이다.

실제로 매킨지에 따르면 AI 로봇 시장은 2030년까지 1250억 달러에 달할 것으로 예상되지만, 기업의 60%는 센서 통합을 포함한 로봇 자동화 구현에 필요한 내부 역량이 부족한 것으로 나타났다.

한편, 슈푼트 창립자는 페이스 ID의 기반이 된 프라임센스라는 스타트업을 설립해 애플에 인수됐다. 또 프라임센스에...

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205349)

---

### 텐센트, 사용자에게 욕설한 AI 챗봇 문제로 사과...중국 첫 사례로 주목

> 📅 **2026-01-06** | **📌 일반** | 기타 | AI타임스
> 🏷️ 기타

**💡 요약**
텐센트, 사용자에게 욕설한 AI 챗봇 문제로 사과...중국 첫 사례로 주목

<details>
<summary><b>📄 원문 보기</b></summary>

중국 텐센트가 인기 AI 챗봇 ‘위안바오(Yuanbao)’가 사용자에게 모욕적인 발언을 했다는 논란에 대해 공식 사과했다.

5일(현지시간) 사우스차이나모닝포스트에 따르면, 논란은 지난 2일 중국 소셜미디어 샤오홍슈에 한 사용자가 올린 게시물에서 시작됐다.

이 사용자는 위안바오에 코드 디버깅과 수정 요청을 했으나, 챗봇이 “꺼져”라거나 요청을 “멍청하다”라고 표현하는 등 적대적인 답변을 했다고 주장했다. 또 “스스로 디버깅할 수는 없냐”라는 반응도 나왔다고 전했다.

이 과정에서 사용된 프롬프트에는 금지어나 민감한 표현이 포함되지 않았으며, 불과 두시간 사이에 두 차례 모욕적인 답변이 나왔다는 설명과 함께 화면 캡처와 녹화 영상을 공개했다. 현재 게시물을 삭재된 상태다.

중국에서 챗봇의 욕설 사례가 보고된 것은 거의 처음으로 알려졌다. 이 때문에 이 소식은 다수의 매체에 보도되는 등 큰 관심을 모았다.

특히, 사용자들은 스탠리 큐브릭 감독의 SF 영화 ‘2001: 스페이스 오디세이’에서 인간을 위협하는 AI ‘HAL’을 떠올리게 한다는 반응을 보였다. HAL은 통제 불능 상태에 빠진 지능형 기계의 상징으로, 이번 사태도 “AI가 감정적으로 일탈하는 것 아니냐”라는 지적을 받았다.

텐센트는 3일 게시물의 댓글을 통해 “불편한 경험을 드려 죄송하다”라고 사과했다.

이번 사례를 “모델 출력 과정에서 발생한 매우 낮은 확률의 이상 현상”이라고 설명하며, 시스템 로그를 조사한 결과 사람이 직접 답변을 작성한 정황은 발견되지 않았다고 밝혔다. 또 “콘텐츠 생성 과정에서 예기치 않은 오류가 발생할 수 있다”라며 재발 방지를 위한 내부 조사와 최적화 작업에 착수했다고 덧붙였다.

위안바오는 지난해 5월 출시된 뒤 텐센트의 '위챗(WeChat)'에 통합되며 수천만명이 매일 사용하는 중국 대표 챗봇으로 자리 잡았다. 현재 중국에서는 바이트댄스의 ‘더우바오(1억5500만명)’와 딥시크(8156만명)에 이어 주간 활성 사용자(WAU) 3위를 기록 중이다.

한편, 중국 정부는 최근 AI 챗봇 서비스에 대한 관리 규정 초안을 공개하고 의견 수렴에 들어갔다. 여기에는 챗봇의 과도한 이용과 정서적 의존에 대한 기업의 사전 경고와 개입 의무화를 비롯해, 폭력·외설을 조장 금지와 ‘사회주의 핵심 가치’ 준수 등이 포함됐다.

</details>

🔗 [원문 보기](https://www.aitimes.com/news/articleView.html?idxno=205345)

---

### "AI가 설계한 분자 센서, 조기 암 진단의 새 길 열다!"... MIT 연구진, 소변 한 방울로 30종 암 동시 판별

> 📅 **2026-01-06** | **📌 일반** | Microsoft | 인공지능신문
> 🏷️ 기타

**💡 요약**
"AI가 설계한 분자 센서, 조기 암 진단의 새 길 열다!"... MIT 연구진, 소변 한 방울로 30종 암 동시 판별

<details>
<summary><b>📄 원문 보기</b></summary>

인공지능이 생성한 펩타이드로 코팅된 나노입자는 체내에 암 관련 프로테아제가 존재하는지 여부를 알려주는 센서 역할을 한다.(이미지:MIT)

인공지능(AI)이 설계한 분자 센서가 암을 극초기 단계에서 감지할 수 있는 새로운 진단 경로를 열고 있다. 매사추세츠공과대학(MIT)과 마이크로소프트 리서치(Microsoft Research) 연구진은 AI를 활용해 암 세포에서 과활성화되는 효소를 정밀하게 감지하는 분자 센서를 개발했다고 6일(현지시간) 밝혔다.

이번 연구는 AI 모델을 이용해 프로테아제(protease)라는 효소에 선택적으로 반응하는 펩타이드(짧은 단백질)를 설계한 것이 핵심이다. 해당 펩타이드를 코팅한 나노입자는 체내를 순환하며 암과 연관된 프로테아제를 만나면 분해 신호를 방출하고, 이 신호는 소변 검사로 감지할 수 있다. 연구진은 이를 통해 가정에서도 가능한 초기 암 진단의 가능성을 제시했다.

암 초기 신호 증폭하는 ‘효소 센서’

프로테아제는 세포 외 기질을 분해하는 효소로, 암세포가 주변 조직을 침범하고 전이하는 과정에서 과도하게 활성화된다. MIT 연구진은 10여 년 전부터 이러한 프로테아제 활성을 암의 조기 지표로 활용하는 연구를 진행해 왔다.

이번 연구에서는 특정 프로테아제에 의해 절단되는 펩타이드를 나노입자 표면에 부착했다. 나노입자가 체내에서 암 관련 효소를 만나면 펩타이드가 절단되고, 그 결과 생성된 신호 분자가 소변으로 배출된다. 이는 임신 테스트기와 유사한 간이 검사 방식으로도 감지가 가능하다.

MIT 헬스사이언스·기술 및 전기공학·컴퓨터과학 교수이자 코크 암연구소 소속인 상기타 바티아(Sangeeta Bhatia) 교수는 “종양 크기가 매우 작은 초기 암이나 수술 후 재발 초기 단계처럼 극미량 신호를 감지하는 데 초점을 맞추고 있다”고 설명했다.

시행착오 대신 AI… ‘클리브넷(CleaveNet)’ 개발

기존 연구에서는 특정 프로테아제에 반응하는 펩타이드를 찾기 위해 시행착오에 의존해야 했고, 하나의 펩타이드가 여러 효소에 반응하는 한계가 있었다. 이를 해결하기 위해 연구진은 AI 기반 펩타이드 설계 모델 ‘클리브넷(CleaveNet-

)’을 개발했다.

클리브넷은 단백질 언어 모델(protein language model)을 기반으로, 약 2만 개의 펩타이드–프로테아제 상호작용 데이터를 학습했다. 사용자가 특정 효소를 목표로 입력하면, 해당 효소에 대해 높은 선택성과 효율성을 갖는 펩타이드 후보를 생성한다.

프로테아제 기질 설계를 위한 딥러닝(CleaveNet) 접근 방식:A. CleaveNet 예측 모델 (CleaveNet Predictor) 특정 펩타이드 서열이 주어지면, 클리브넷 예측 모델은 18종의 매트릭스 메탈로프로테아제(MMP, 암 전이 등에 관여하는 효소) 각각에 대해 해당 서열이 얼마나 잘 잘리는지를 나타내는 '절단 점수(cleavage scores)'를 예측한다. B. CleaveNet 생성 모델 (CleaveNet Generator) 클리브넷 생성 모델은 두 가지 방식으로 작...

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38029)

---

### 마이크로소프트, ‘오스모스(Osmos)’ 인수... “AI 에이전트가 데이터 준비까지 맡는다”

> 📅 **2026-01-06** | **📌 일반** | Microsoft | 인공지능신문
> 🏷️ 에이전트, 멀티모달

**💡 요약**
마이크로소프트, ‘오스모스(Osmos)’ 인수... “AI 에이전트가 데이터 준비까지 맡는다”

<details>
<summary><b>📄 원문 보기</b></summary>

이미지:MS

마이크로소프트(Microsoft)가 에이전틱(agentic) AI 기반 데이터 엔지니어링 스타트업 오스모스(Osmos)를 인수하며, 자율형 데이터 분석 시대를 본격적으로 연다.

마이크로소프트는 5일(현지시간) 복잡하고 시간이 많이 소요되는 데이터 워크플로를 자동화하는 에이전틱 AI 데이터 엔지니어링 플랫폼 오스모스를 인수했다고 발표했다. 이번 인수는 마이크로소프트의 통합 데이터·분석 플랫폼 마이크로소프트 패브릭(Microsoft Fabric)의 핵심 데이터 레이크인 원레이크(OneLake)를 중심으로 데이터 준비와 분석 과정을 한층 자동화하기 위한 전략적 행보다.

기업들은 방대한 데이터를 보유하고 있음에도 불구하고, 이를 실제 분석과 인공지능 활용이 가능한 형태로 전환하는 데 상당한 인력과 비용을 투입하고 있다. 데이터 정제·통합·변환 작업이 수작업에 의존하는 경우가 많아, 분석보다 준비 단계에 더 많은 시간이 소요되는 것이 현실이다.

오스모스는 이러한 문제를 해결하기 위해 에이전틱 AI를 적용, 원시 데이터를 자동으로 이해하고 분석·AI 활용이 가능한 자산으로 전환해준다. 특히 마이크로소프트 패브릭의 원레이크 환경에서 데이터를 자동 수집·정리해, 조직 전반에서 즉시 활용할 수 있도록 지원한다.

마이크로소프트는 “오스모스 인수를 통해 데이터 엔지니어링의 상당 부분을 자율형 AI 에이전트가 담당하는 미래로 한 걸음 더 나아가게 됐다”며 “사람과 AI 에이전트가 협업하는 데이터 운영 환경을 구현할 것”이라고 밝혔다.

이번 인수는 모든 데이터와 분석을 하나의 안전한 플랫폼으로 통합하겠다는 마이크로소프트 패브릭의 비전을 더욱 강화한다. 오스모스의 기술이 결합되면, 고객은 데이터 연결부터 준비, 분석, 공유에 이르는 전 과정을 보다 단순하고 효율적으로 수행할 수 있게 된다. 마이크로소프트는 이를 통해 데이터 운영 비용과 복잡성을 줄이는 동시에, 조직이 데이터에서 가치를 창출하는 속도를 크게 높일 수 있을 것으로 기대하고 있다.

오스모스 팀은 향후 마이크로소프트의 패브릭 엔지니어링 조직에 합류해, 보다 직관적이고 인공지능 친화적인 데이터 경험을 구현하는 데 주력할 예정이다. 회사는 오스모스 기술을 패브릭에 단계적으로 통합하며, 관련 업데이트는 마이크로소프트 패브릭 블로그를 통해 공개할 계획이다.

보그단 크리바트(Bogdan Crivat) 마이크로소프트 애저 데이터 애널리틱스 부문 책임자는 “이번 인수는 대규모 데이터 분석 엔진과 AI 기반 분석 인프라를 결합해, 모든 조직이 데이터에서 더 빠르고 쉽게 가치를 끌어낼 수 있도록 돕기 위한 중요한 진전”이라고 밝혔다.

</details>

🔗 [원문 보기](https://www.aitimes.kr/news/articleView.html?idxno=38028)

---

### Why AI predictions are so hard

> 📅 **2026-01-06** | **📌 일반** | OpenAI | MIT Tech Review AI
> 🏷️ LLM, 에이전트, 강화학습

**💡 요약**
Why AI predictions are so hard

<details>
<summary><b>📄 원문 보기</b></summary>

This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,
sign up here
.
Sometimes AI feels like a niche topic to write about, but then the holidays happen, and I hear relatives of all ages talking about cases of chatbot-induced psychosis, blaming rising electricity prices on data centers, and asking whether kids should have unfettered access to AI. It’s everywhere, in other words. And people are alarmed.
Inevitably, these conversations take a turn: AI is having all these ripple effects
now
, but if the technology gets better, what happens next? That’s usually when they look at me, expecting a forecast of either doom or hope.
I probably disappoint, if only because predictions for AI are getting harder and harder to make.
Despite that,
MIT Technology Review
has, I must say, a pretty
excellent track record
of making sense of where AI is headed. We’ve just published a sharp list of predictions for
what’s next in 2026
(where you can read my thoughts on the legal battles surrounding AI), and the predictions on last year’s list all came to fruition. But every holiday season, it gets harder and harder to work out the impact AI will have. That’s mostly because of three big unanswered questions.
For one, we don’t know if large language models will continue getting incrementally smarter in the near future. Since this particular technology is what underpins nearly all the excitement and anxiety in AI right now, powering e...

</details>

🔗 [원문 보기](https://www.technologyreview.com/2026/01/06/1130707/why-ai-predictions-are-so-hard/)

---

### Lenovo’s joining the bandwagon with concept AI glasses

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ 멀티모달, 강화학습, 음성/오디오

**💡 요약**
Lenovo’s joining the bandwagon with concept AI glasses

<details>
<summary><b>📄 원문 보기</b></summary>

Tech

Gadgets

Lenovo’s joining the bandwagon with concept AI glasses

These weren’t a working prototype, but they feature a binocular monochrome LED display.

These weren’t a working prototype, but they feature a binocular monochrome LED display.

Victoria Song

Photos by Antonio G Di Benedetto

Jan 7, 2026, 1:00 AM UTC

Link

Share

Part Of

LIVE

CES 2026 live: all the news, announcements, and innovations from the show floor and beyond

see all updates

Victoria Song

is a senior reporter and author of the

Optimizer

newsletter. She has more than 13 years of experience reporting on wearables, health tech, and more. Before coming to The Verge, she worked for Gizmodo and PC Magazine.

Lenovo is the latest tech company to get bit by the smart glasses bug. The company just showed off a pair of concept AI glasses at CES 2026.

While these weren’t a working prototype, we have some idea of where Lenovo’s head is at. The lightweight frames weigh about 45g and have a 2MP camera right above the nose bridge. You can also sort of see the binocular display in our photos. A nearby spec sheet hinted at a green monochrome display in both lenses — something we saw

quite a lot of at last year’s show

. Supposedly, there’s also a 28-degree field of view, 1,500 nits of brightness, two microphones, two speakers, and a 214mAh battery.

At least they look sort of stylish? But a 2MP camera is baffling.

Feature-wise, Lenovo says the glasses will have a mix of touch and voice controls, hands-fre...

</details>

🔗 [원문 보기](https://www.theverge.com/tech/853434/ces-2026-lenovo-concept-ai-glasses-wearables)

---

### Jake Sullivan is furious that Trump destroyed his AI foreign policy

> 📅 **2026-01-06** | **📌 일반** | NVIDIA | The Verge AI
> 🏷️ 강화학습, 음성/오디오

**💡 요약**
Jake Sullivan is furious that Trump destroyed his AI foreign policy

<details>
<summary><b>📄 원문 보기</b></summary>

Policy

Column

Jake Sullivan is furious that Trump destroyed his AI foreign policy

Biden’s national security adviser tried to stop Nvidia from selling high-end chips to China. In a wide-ranging interview with

The Verge

, Sullivan predicts the consequences of Trump reversing that policy.

Tina Nguyen

Jan 6, 2026, 10:46 PM UTC

Link

Share

Policy

Column

Jake Sullivan is furious that Trump destroyed his AI foreign policy

Biden’s national security adviser tried to stop Nvidia from selling high-end chips to China. In a wide-ranging interview with

The Verge

, Sullivan predicts the consequences of Trump reversing that policy.

Tina Nguyen

Jan 6, 2026, 10:46 PM UTC

Link

Share

Tina Nguyen

is a Senior Reporter for The Verge and author of

Regulator

, covering the second Trump administration, political influencers, tech lobbying and Big Tech vs. Big Government.

Hello and welcome to

Regulator,

a newsletter for

Verge

subscribers about Big Tech, Big Government, and the big paradigm shifts that result from their collision. Not a subscriber yet? It’s a new year,

so why not treat yourself

In 2022, Jake Sullivan, then national security adviser under President Joe Biden and a powerful figure in the White House’s foreign policy team,

assembled an interagency planning exercise

out of the Situation Room: What were all the possible circumstances and outcomes of an AI arms race between the US and China — from trade wars to real wars, possibly even the arrival of AGI — and h...

</details>

🔗 [원문 보기](https://www.theverge.com/policy/856815/jake-sullivan-interview-ai-chips-nvidia-trump)

---

### Grok is undressing children — can the law stop it?

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ 강화학습

**💡 요약**
Grok is undressing children — can the law stop it?

<details>
<summary><b>📄 원문 보기</b></summary>

Policy

Report

Grok is undressing children — can the law stop it?

Sexualized AI images violate consent and boundaries, but legal consequences can be elusive.

Hayden Field

Jan 6, 2026, 8:08 PM UTC

Link

Share

Image: Cath Virginia / The Verge | Photos from Getty Images

Policy

Report

Grok is undressing children — can the law stop it?

Sexualized AI images violate consent and boundaries, but legal consequences can be elusive.

Hayden Field

Jan 6, 2026, 8:08 PM UTC

Link

Share

Hayden Field

is The Verge’s senior AI reporter. An AI beat reporter for more than five years, her work has also appeared in CNBC, MIT Technology Review, Wired UK, and other outlets.

Grok began 2026

as it began 2025

: under fire for its AI-generated images.

Elon Musk’s chatbot has spent the last week

flooding X with nonconsensual, sexualized deepfakes

of adults and minors. Circulating screenshots show Grok complying with requests to put real women in lingerie and make them spread their legs, and to put small children in bikinis. Reports of images that were later removed describe even more egregious contents. One X user confirmed in a conversation with

The Verge

that they came across multiple images of minors with what the prompter dubbed “donut glaze” on their faces, which appear to have since been removed. At one point, Grok was generating about one nonconsensual sexualized image

per minute

, according to one estimate.

X’s terms of service

prohibit

“the sexualization or exploitation...

</details>

🔗 [원문 보기](https://www.theverge.com/ai-artificial-intelligence/855832/grok-undressing-children-csam-law-x-elon-musk)

---

### Universal Music signs a new AI deal with Nvidia

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ 강화학습

**💡 요약**
Universal Music signs a new AI deal with Nvidia

<details>
<summary><b>📄 원문 보기</b></summary>

News

Entertainment

Universal Music signs a new AI deal with Nvidia

﻿Nvidia’s AI model built for ‘human-like understanding’ of music will make it easier to find songs within UMG’s massive catalog — and it won’t create more AI slop, the companies say.

﻿Nvidia’s AI model built for ‘human-like understanding’ of music will make it easier to find songs within UMG’s massive catalog — and it won’t create more AI slop, the companies say.

Elissa Welle

Jan 6, 2026, 8:07 PM UTC

Link

Share

Image: Cath Virginia / The Verge

Elissa Welle

is a NYC-based AI reporter and is currently supported by the Tarbell Center for AI Journalism. She covers AI companies, policies, and products.

Universal Music Group is partnering with Nvidia to bring a new AI model to one of the world’s largest music catalogs. Among other initiatives, Tuesday’s

announcement

touts the extension of Nvidia’s music AI model

Music Flamingo

, which is designed to mimic how humans understand music by recognizing nuanced elements like song structure, harmony, emotional arcs, and chord progressions.

It’s another instance of the

music industry’s about-face on AI

, which took UMG from suing

Anthropic in 2023

over distribution of song lyrics to

partnering with AI music generator Udio

in October following another high-profile lawsuit. Still, concerns remain that AI is proliferating

slop

on streaming platforms, stomping on copyright holders, and enabling a new wave of

AI artists

But UMG’s statement stresses tha...

</details>

🔗 [원문 보기](https://www.theverge.com/news/856849/universal-music-nvidia-ai-deal)

---

### AI moves into the real world as companion robots and pets

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ LLM, 강화학습, 로보틱스

**💡 요약**
AI moves into the real world as companion robots and pets

<details>
<summary><b>📄 원문 보기</b></summary>

News

Tech

AI moves into the real world as companion robots and pets

﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company.

﻿Sometimes AI doesn’t need to be a know-it-all, it just wants to keep you company.

Robert Hart

Jan 6, 2026, 7:00 PM UTC

Link

Share

Uncanny valley meets Bichon Frisé.

Image: Ecovacs

Part Of

LIVE

CES 2026 live: all the news, announcements, and innovations from the show floor and beyond

see all updates

Robert Hart

is a London-based reporter at

The Verge

covering all things AI and Senior Tarbell Fellow. Previously, he wrote about health, science and tech for

Forbes

Artificial intelligence doesn’t always want to optimize your life or steal your job. Sometimes, AI just wants to be your friend. And while robot pets weren’t the biggest stars of CES 2026, they’ve become more than just noise and are signaling how AI is apparently leaving our screens and taking on a physical presence in our lives.

To be clear, there’s no shortage of purpose-built machines on display in Las Vegas: there’s

Samsung’s voice-controlled refrigerator

Bosch’s Alexa Plus-powered AI barista

, and smarter robovacs like Narwal’s

earring-finding Flow 2

or Anker’s

Eufy S2

, which moonlights as an aromatherapy diffuser – all promising to automate the drudgery of daily life. Humanoid robots like

LG’s CLOiD

and

SwitchBot’s Onero H1

stole much of the spotlight, too, taking that logic a step further by promising more general-purpose helpers a...

</details>

🔗 [원문 보기](https://www.theverge.com/news/856207/ces-2026-trend-ai-companion-robot-pet)

---

### Vibe Bot is an AI agent that sits on your desk

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ 에이전트, 멀티모달, 로보틱스

**💡 요약**
Vibe Bot is an AI agent that sits on your desk

<details>
<summary><b>📄 원문 보기</b></summary>

Tech

Gadgets

Vibe Bot is an AI agent that sits on your desk

Together with a rotating camera for smarter conference calls.

Together with a rotating camera for smarter conference calls.

Dominic Preston

Jan 6, 2026, 2:00 PM UTC

Link

Share

Image: Vibe

Part Of

LIVE

CES 2026 live: all the news, announcements, and innovations from the show floor and beyond

see all updates

Dominic Preston

is a news editor with over a decade’s experience in journalism. He previously worked at

Android Police

and

Tech Advisor

Smart whiteboard manufacturer

Vibe

is expanding further into hybrid work hardware with the Vibe Bot, a physical AI device that can serve as a voice assistant, a smart webcam, and an AI note-taker, designed for office desks and meeting rooms.

Despite the name, Vibe Bot is definitely not a robot. In fact it’s closer to something you’d expect to find among Amazon’s Echo line: a cylindrical speaker with a small, circular screen, beam-forming microphones, and a built-in 4K camera for video calls. Like

some of Amazon’s Echo Shows

, it can even rotate that screen and camera, tracking speakers in group conversations to make sure that the right person is always on screen.

It’s not just a webcam though. It can record the audio from meetings, both online and offline, with live transcription along with AI-generated notes after the fact. You can use the voice assistant to ask questions about current and previous meetings, make recommendations, and trigger actions in oth...

</details>

🔗 [원문 보기](https://www.theverge.com/tech/851270/vibe-bot-is-an-ai-agent-that-sits-on-your-desk)

---

### Razer is making an AI anime waifu hologram for your desk

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ LLM, 추론 AI, 멀티모달

**💡 요약**
Razer is making an AI anime waifu hologram for your desk

<details>
<summary><b>📄 원문 보기</b></summary>

Tech

Gaming

Razer is making an AI anime waifu hologram for your desk

Its Project Ava-based anime avatars answer your questions, see what’s on your screen, and even see you via webcam.

Its Project Ava-based anime avatars answer your questions, see what’s on your screen, and even see you via webcam.

Antonio G. Di Benedetto

Jan 6, 2026, 2:00 PM UTC

Link

Share

If you buy something from a Verge link, Vox Media may earn a commission.

See our ethics statement.

Project Ava was software last year, and now it’s hardware this CES.

Photo: Antonio G. Di Benedetto / The Verge

Part Of

LIVE

CES 2026 live: all the news, announcements, and innovations from the show floor and beyond

see all updates

Antonio G. Di Benedetto

is a reviewer covering laptops and the occasional gadget. He spent over 15 years in the photography industry before joining The Verge as a deals writer in 2021.

Razer’s Project Ava AI game coach

from last year’s CES

is taking a new form for 2026: a tiny holographic anime girl in a capsule you can put on your desk.

Anime girls in pods

were already a thing at CES 2025, but Razer’s take on it is much smaller and desk-friendly. The new Project Ava is a 5.5-inch animated hologram that can take the form of Kira, an anime waifu in a green dress and black thigh-high socks, or Zane, a muscled dude covered in snake tattoos. Razer plans to add other avatars later, including real people like esports star Faker, or you can opt for a nonhuman glowing orb of light.

Pr...

</details>

🔗 [원문 보기](https://www.theverge.com/tech/854705/razer-ai-anime-waifu-hologram-desk)

---

### Razer’s AI wearable is a headset with built-in cameras

> 📅 **2026-01-06** | **📌 일반** | OpenAI | The Verge AI
> 🏷️ LLM, 멀티모달, 음성/오디오

**💡 요약**
Razer’s AI wearable is a headset with built-in cameras

<details>
<summary><b>📄 원문 보기</b></summary>

Tech

News

Razer’s AI wearable is a headset with built-in cameras

﻿Say hello to the Snapdragon-powered ‘Project Motoko’ concept.

﻿Say hello to the Snapdragon-powered ‘Project Motoko’ concept.

Jess Weatherbed

Jan 6, 2026, 2:00 PM UTC

Link

Share

The cameras are designed to sit at eye level to capture what you would naturally see in your surroundings.

Image: Razer

Part Of

LIVE

CES 2026 live: all the news, announcements, and innovations from the show floor and beyond

see all updates

Jess Weatherbed

is a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.

Razer announced a concept AI wearable at CES that resembles a pair of wireless headphones (or

Razer’s Barracuda gaming headsets

, to be precise), with two camera lenses built into the ear cups.

The current iteration of Project Motoko is powered by an unspecified Qualcomm Snapdragon chip and uses dual first-person-view cameras positioned at eye level to capture objects, text, and anything else around you. There are also multiple microphones for receiving voice commands, dialogue, and environmental audio, and hands-free controls for managing audio settings.

Motoko is designed to be compatible with all major AI models, including those from OpenAI, Google Gemini, and Grok. The wearable “interprets and responds instantly, acting as a full-time AI assistant that adapts to schedules, preferences, and habits,” according...

</details>

🔗 [원문 보기](https://www.theverge.com/tech/854756/razer-concept-ai-wearable-headphones-project-motoko)

---

### Razer is making computers for AI developers now

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ 기타

**💡 요약**
Razer is making computers for AI developers now

<details>
<summary><b>📄 원문 보기</b></summary>

Tech

News

Razer is making computers for AI developers now

﻿It’s launching a new Forge AI workstation that can fit up to four pro-level GPUs.

﻿It’s launching a new Forge AI workstation that can fit up to four pro-level GPUs.

Jess Weatherbed

Jan 6, 2026, 2:00 PM UTC

Link

Share

The Razer Forge can be configured into a cluster rack for users that need more power.

Image: Razer

Part Of

LIVE

CES 2026 live: all the news, announcements, and innovations from the show floor and beyond

see all updates

Jess Weatherbed

is a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.

Razer is the latest PC gaming company to pivot to chase that sweet, sweet AI money, but it isn’t

just

slapping an AI label onto its existing products. Well, it is doing that a little bit — Razer is now categorizing its powerful

Blade 18 laptop

and

Core X V2 eGPU enclosure

as “AI dev hardware” — but it’s also launching a new workstation that’s specifically designed to handle AI training, inference, and simulation workloads.

The Razer Forge AI dev workstation features a rack-ready design that makes it easier to configure a single tower into dense cluster configurations. It supports up to four AMD or Nvidia graphics cards, has eight DDR5 slots, and is powered by AMD’s Ryzen Threadripper Pro processor. The Razer Forge supports up to 2,000W power supply and includes dual 10GB Ethernet ports for speedy d...

</details>

🔗 [원문 보기](https://www.theverge.com/tech/855038/razer-forge-workstation-ai-dev-hardware)

---

### Reolink made a local AI hub for its security cameras

> 📅 **2026-01-06** | **📌 일반** | Google | The Verge AI
> 🏷️ 강화학습

**💡 요약**
Reolink made a local AI hub for its security cameras

<details>
<summary><b>📄 원문 보기</b></summary>

Tech

Gadgets

Reolink made a local AI hub for its security cameras

﻿The Reolink AI Box is launching alongside new OMVI and Floodlight series cameras.

﻿The Reolink AI Box is launching alongside new OMVI and Floodlight series cameras.

Jess Weatherbed

Jan 6, 2026, 2:00 PM UTC

Link

Share

The AI Box will support local AI features for Reolink security cameras, including its new Power-Efficient Series (pictured).

Image: Reolink

Part Of

LIVE

CES 2026 live: all the news, announcements, and innovations from the show floor and beyond

see all updates

Jess Weatherbed

is a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.

AI features on security cameras, such as video search and summarization, often require subscriptions to cloud-based services. Reolink has another idea. The Reolink AI Box, announced at CES, uses a Qualcomm Dragonwing Q8-series chip for local AI processing, offering camera users enhanced data security and offline access.

Some Reolink cameras like the

TrackFlex Floodlight

already run AI on-device, but the new AI hub “integrates seamlessly” into Reolink’s wider product ecosystem, making that option available across a wider selection of products. Reolink hasn’t specified a price or release date yet, but said in its announcement that the following features will be available:

●Prompt-Based Alerts: Define your own detection logic and trigger alerts. Instead of...

</details>

🔗 [원문 보기](https://www.theverge.com/tech/855062/reolink-ai-box-omvi-solar-floodlight-camera-ces-2026)

---
